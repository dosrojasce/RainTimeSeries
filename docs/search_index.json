[["index.html", "Análisis de Series Temporales de Lluvia: Estación VENADO ORO VIVERO [21205580] Sección 1 Importancia del Análisis de la Precipitación", " Análisis de Series Temporales de Lluvia: Estación VENADO ORO VIVERO [21205580] Dónoban Rojas Sección 1 Importancia del Análisis de la Precipitación Se propone el análisis de los datos de precipitación diaria registrados en la estación climatológica “VENADO ORO VIVERO”, ubicada en Bogotá, con coordenadas 4.60° de latitud y -74.06° de longitud, y una altitud de 2,725 metros sobre el nivel del mar. Esta estación, parte de la red del Instituto de Hidrología, Meteorología y Estudios Ambientales (IDEAM), cuenta con datos históricos desde el 1 de agosto de 1965 hasta el 10 de agosto de 2022. La variable seleccionada es la precipitación diaria (PTPM_CON), medida en milímetros (mm). Justificación del uso de datos de precipitación El análisis de las series temporales de precipitación es fundamental para comprender las características climáticas locales y su evolución a lo largo del tiempo. Este tipo de estudio permite identificar patrones estacionales, tendencias a largo plazo y fenómenos extremos, aspectos cruciales para pronosticar eventos climáticos relevantes. La estación VENADO ORO VIVERO ha sido seleccionada por su accesibilidad de datos y su cercanía a la Pontificia Universidad Javeriana sede Bogotá, donde actualmente se lleva a cabo una investigación aplicada sobre Sistemas Urbanos de Drenaje Sostenible (SuDS) en el contexto del cambio climático. Los datos locales de precipitación son esenciales para la predicción de escenarios climáticos futuros, lo que facilitará la adaptación y optimización de los SuDS ante las variaciones climáticas proyectadas. A pesar de que la serie temporal de la estación VENADO ORO VIVERO abarca más de cinco décadas, es relevante señalar que presenta algunas lagunas en los registros. Sin embargo, esta serie proporciona una base valiosa para el análisis de tendencias, estacionalidad, autocorrelación y el desarrollo de modelos predictivos. El valor añadido de este análisis radica en la aplicación de técnicas avanzadas de series temporales, que permitirán no solo detectar patrones climáticos recurrentes, sino también identificar anomalías y cambios estructurales en las precipitaciones. El enfoque de este estudio se centra en el desarrollo de competencias técnicas y en el manejo de herramientas estadísticas aplicables a diversos contextos de análisis climático. Aunque los datos pueden ser útiles para futuras investigaciones, como el modelado hidrológico o el análisis del cambio climático, su proximidad a la Pontificia Universidad Javeriana los convierte en especialmente relevantes en el marco de la investigación en curso sobre SuDS. Fuentes y permisos Los datos utilizados provienen del Instituto de Hidrología, Meteorología y Estudios Ambientales (IDEAM), específicamente a través de la plataforma pública DHIME (http://dhime.ideam.gov.co/atencionciudadano/). DHIME es un sistema de acceso público que permite la consulta y descarga de datos meteorológicos e hidrológicos. Estos datos están disponibles sin restricciones para fines académicos e investigativos, cumpliendo con las políticas de uso del IDEAM. Adicionalmente, los datos obtenidos a través de la plataforma del IDEAM están disponibles para su verificación y consulta en el repositorio oficial, accesible en el siguiente enlace: Descargar datos "],["analisisexploratorio.html", "Sección 2 Análisis Exploratorio 2.1 Datos Faltantes 2.2 Análisis de la Serie Temporal 2.3 Análisis de Resultados", " Sección 2 Análisis Exploratorio La estación ha estado operando de manera continua desde el 15 de agosto de 1965. No obstante, como es común en este tipo de datos, pueden presentarse períodos en los que los instrumentos de medición fallen o presenten anomalías operativas. Estos fallos pueden generar periodos de ausencia de datos, lo cual es una limitación que debe ser considerada en el análisis. La existencia de datos faltantes es, por tanto, un aspecto fundamental que requiere ser evaluado y tratado adecuadamente en la fase de análisis exploratorio. 2.1 Datos Faltantes A continuación, se presentará el proceso realizado para identificar y tratar los datos faltantes en la serie temporal de precipitación diaria. El primer paso consiste en la preparación y filtrado de los datos para asegurar que solo se mantengan las variables de interés, en este caso, la fecha y el valor de precipitación diaria medida en milímetros. Code df &lt;- df[, c(&quot;Fecha&quot;, &quot;Valor&quot;)] Para asegurar que el formato de la columna Fecha es adecuado para el análisis temporal, se ha convertido esta variable a un formato de fecha estándar. Además, se ha generado una secuencia completa de fechas que cubre todo el rango temporal de los datos disponibles, desde la fecha mínima hasta la máxima. Este paso es crucial, ya que el dataframe original no contiene registros para las fechas no reportadas, lo cual es esencial para observar y analizar los rangos de tiempo en los que los datos están ausentes. Code # Asegurarse de que la columna Fecha esté en formato de fecha df$Fecha &lt;- as.Date(df$Fecha) # 1. Crear una secuencia completa de fechas fecha_completa &lt;- seq(min(df$Fecha), max(df$Fecha), by = &quot;day&quot;) # 2. Unir con los datos originales df_completo &lt;- data.frame(Fecha = fecha_completa) %&gt;% left_join(df, by = &quot;Fecha&quot;) Una vez completada la secuencia de fechas, se identificaron los períodos en los que los datos de precipitación están ausentes. Code # 3. Identificar rangos de datos faltantes df_completo$es_faltante &lt;- is.na(df_completo$Valor) rangos_faltantes &lt;- rle(df_completo$es_faltante) inicio_faltantes &lt;- cumsum(c(1, rangos_faltantes$lengths[-length(rangos_faltantes$lengths)])) fin_faltantes &lt;- cumsum(rangos_faltantes$lengths) rangos &lt;- data.frame( inicio = df_completo$Fecha[inicio_faltantes[rangos_faltantes$values]], fin = df_completo$Fecha[fin_faltantes[rangos_faltantes$values]], duracion = rangos_faltantes$lengths[rangos_faltantes$values] ) %&gt;% filter(duracion &gt; 0) # 5. Imprimir resultados datatable(rangos, options = list(pageLength = 10, lengthMenu = c(5, 10, 25, 50), scrollX = TRUE), filter = &#39;top&#39;, rownames = FALSE) %&gt;% formatDate(&#39;inicio&#39;, method = &#39;toLocaleDateString&#39;) %&gt;% formatDate(&#39;fin&#39;, method = &#39;toLocaleDateString&#39;) A partir del análisis de los rangos de datos faltantes, se observó que existen 218 intervalos con datos ausentes. Para entender mejor la distribución de estos intervalos, se realizó una visualización temporal de los datos faltantes. Code # 6. Visualización de datos faltantes ggplot(df_completo, aes(x = Fecha, y = 1)) + geom_point(aes(color = es_faltante), shape = 15, size = 3, alpha = 0.8) + scale_color_manual(values = c(&quot;FALSE&quot; = &quot;lightgreen&quot;, &quot;TRUE&quot; = &quot;tomato&quot;), # Colores claros y brillantes labels = c(&quot;Presente&quot;, &quot;Faltante&quot;)) + scale_x_date(date_breaks = &quot;3 year&quot;, date_labels = &quot;%Y&quot;) + # Etiquetas cada 3 años theme_minimal() + labs(title = &quot;Visualización de Datos Faltantes&quot;, x = &quot;Fecha&quot;, y = &quot;&quot;, color = &quot;Estado del Dato&quot;) + theme( plot.background = element_rect(fill = &quot;black&quot;, color = NA), # Fondo oscuro panel.background = element_rect(fill = &quot;black&quot;), # Fondo del panel oscuro plot.title = element_text(hjust = 0.5, size = 16, face = &quot;bold&quot;, color = &quot;white&quot;), axis.text.x = element_text(angle = 45, hjust = 1, size = 10, color = &quot;white&quot;), axis.text.y = element_blank(), # Eliminar texto del eje y axis.ticks.y = element_blank(), # Eliminar ticks del eje y legend.position = &quot;top&quot;, legend.text = element_text(color = &quot;white&quot;), # Texto blanco para la leyenda legend.title = element_text(color = &quot;white&quot;), # Título blanco para la leyenda panel.grid.major = element_line(color = &quot;gray&quot;), # Cuadrícula gris tenue panel.grid.minor = element_blank() # Eliminar cuadrícula menor ) En el gráfico anterior, es evidente que existen períodos prolongados de datos faltantes. Para profundizar en este aspecto, se identificó el intervalo más largo de datos ausentes y se determinó su duración. Code # 7. Rango máximod e datos faltantes # Filtrar el dataframe para obtener la fila donde la duración es máxima fila_maxima &lt;- rangos %&gt;% filter(duracion == max(duracion)) fila_maxima ## inicio fin duracion ## 1 2005-08-29 2007-11-21 815 Se ha identificado un intervalo de 815 días sin datos, lo que corresponde a un período superior a dos años. Este hallazgo plantea un desafío significativo, ya que los períodos de datos faltantes tan extensos podrían introducir sesgos o distorsiones en el análisis, afectando tanto la calidad de los modelos como la validez de las conclusiones. Este intervalo de datos ausentes podría dificultar la identificación de patrones temporales consistentes y alterar las predicciones que se obtengan de los modelos basados en series temporales. Dado lo anterior, se justifica la decisión de iniciar el análisis a partir del 22 de noviembre de 2007, una fecha posterior a este intervalo de datos faltantes. Al excluir los datos previos a esta fecha, se asegura la integridad temporal de la serie, garantizando que los modelos y las conclusiones se basen en un conjunto de datos con menor cantidad de lagunas temporales. Esto no solo mejora la coherencia de las observaciones, sino que también optimiza la capacidad de los modelos de aprendizaje automático para capturar patrones de comportamiento en los datos. En definitiva, esta selección busca minimizar el impacto de los largos períodos sin datos y maximizar la robustez de los análisis posteriores. A continuación, se realiza el filtrado de los datos a partir de esta fecha clave para continuar con el análisis sin los períodos de datos faltantes anteriores. La operación se ejecuta de la siguiente manera: Code # Filtrar los datos a partir del 22 de noviembre de 2007 fecha_inicio &lt;- as.Date(&quot;2007-11-22&quot;) df_filtrado &lt;- df_completo %&gt;% filter(Fecha &gt;= fecha_inicio) # Verificar el dataframe resultante head(df_filtrado) ## Fecha Valor es_faltante ## 1 2007-11-22 14.8 FALSE ## 2 2007-11-23 0.3 FALSE ## 3 2007-11-24 0.8 FALSE ## 4 2007-11-25 0.5 FALSE ## 5 2007-11-26 0.1 FALSE ## 6 2007-11-27 0.4 FALSE Una vez realizados los ajustes en la serie temporal, se vuelve a evaluar la presencia de datos faltantes en el nuevo conjunto. Se identifican los rangos de fechas donde faltan datos, lo cual es esencial para determinar si es necesario proceder con una imputación. Code # 3. Identificar rangos de datos faltantes en el dataframe filtrado df_filtrado$es_faltante &lt;- is.na(df_filtrado$Valor) rangos_faltantes &lt;- rle(df_filtrado$es_faltante) inicio_faltantes &lt;- cumsum(c(1, rangos_faltantes$lengths[-length(rangos_faltantes$lengths)])) fin_faltantes &lt;- cumsum(rangos_faltantes$lengths) rangos &lt;- data.frame( inicio = df_filtrado$Fecha[inicio_faltantes[rangos_faltantes$values]], fin = df_filtrado$Fecha[fin_faltantes[rangos_faltantes$values]], duracion = rangos_faltantes$lengths[rangos_faltantes$values] ) %&gt;% filter(duracion &gt; 0) # Filtrar el dataframe para obtener la fila donde la duración es máxima fila_maxima &lt;- rangos %&gt;% filter(duracion == max(duracion)) fila_maxima ## inicio fin duracion ## 1 2013-07-01 2013-07-31 31 ## 2 2013-10-01 2013-10-31 31 El análisis de los datos revela que los períodos de ausencias de datos más prolongados en el conjunto filtrado no exceden los 31 días (aproximadamente un mes), lo que facilita significativamente su imputación en comparación con los intervalos de más de dos años que se observaban en el conjunto de datos anterior. Esta reducción en la longitud de los períodos faltantes ofrece una ventaja considerable para los métodos de imputación, ya que se puede trabajar con ventanas de tiempo más cortas y coherentes. Para abordar la imputación de los datos faltantes, se optó por utilizar el valor promedio de la precipitación en el mismo día a lo largo de los años en los que se dispone de información, con el fin de mantener la estacionalidad de la serie temporal y asegurar que la imputación refleje las variaciones históricas típicas. A continuación se muestra el procedimiento implementado: Code df_filtrado &lt;- df_filtrado %&gt;% mutate( Año = year(Fecha), DiadelAño = yday(Fecha) ) # Función para imputar usando el promedio del mismo día en otros años imputar_estacional &lt;- function(x) { df_imputacion &lt;- df_filtrado %&gt;% group_by(DiadelAño) %&gt;% summarise(ValorPromedio = mean(Valor, na.rm = TRUE)) x_imputado &lt;- x for (i in which(is.na(x))) { dia_del_año &lt;- yday(df_filtrado$Fecha[i]) x_imputado[i] &lt;- df_imputacion$ValorPromedio[df_imputacion$DiadelAño == dia_del_año] } return(x_imputado) } # Aplicar la imputación df_filtrado$ValorImputado &lt;- imputar_estacional(df_filtrado$Valor) Con los datos imputados y completos, ya contamos con la información necesaria para proceder al análisis detallado de la serie temporal, lo que nos permitirá identificar patrones, tendencias y realizar proyecciones precisas sobre la precipitación en la estación estudiada. 2.2 Análisis de la Serie Temporal Code # Crear una serie temporal ts_lluvia &lt;- ts(df_filtrado$ValorImputado, frequency = 365, start = c(year(min(df_filtrado$Fecha)), yday(min(df_filtrado$Fecha)))) # 1. Gráfico de la serie temporal original par(bg = &quot;black&quot;, col.axis = &quot;white&quot;, col.lab = &quot;white&quot;, col.main = &quot;white&quot;, fg = &quot;white&quot;) plot(ts_lluvia, main = &quot;Serie Temporal de Precipitación Diaria&quot;, ylab = &quot;Precipitación (mm)&quot;, xlab = &quot;Año&quot;, col = &quot;lightblue&quot;) La serie temporal de precipitación diaria muestra una marcada variabilidad, con valores que oscilan entre 0 y 60 mm. Ocasionalmente, se observan picos que superan los 50 mm, evidenciando la ocurrencia de eventos extremos de precipitación. Hacia los años más recientes, en particular el 2020, se aprecia una ligera tendencia hacia la disminución en la intensidad de las precipitaciones. Code # 2. Promedio Móvil # Calcular promedio móvil de 30 días ma_30 &lt;- rollmean(ts_lluvia, k = 30, fill = NA) # Gráfico del promedio móvil par(bg = &quot;black&quot;, col.axis = &quot;white&quot;, col.lab = &quot;white&quot;, col.main = &quot;white&quot;, fg = &quot;white&quot;) plot(ts_lluvia, main = &quot;Serie Temporal con Promedio Móvil de 30 días&quot;, ylab = &quot;Precipitación (mm)&quot;, xlab = &quot;Año&quot;, col = &quot;lightblue&quot;) lines(ma_30, col = &quot;red&quot;, lwd = 2) legend(&quot;topright&quot;, legend = c(&quot;Original&quot;, &quot;Promedio Móvil 30 días&quot;), col = c(&quot;lightblue&quot;, &quot;red&quot;), lty = 1, bg = &quot;black&quot;, text.col = &quot;white&quot;) El promedio móvil de 30 días, representado por la línea roja, resalta patrones estacionales más claros que no se perciben fácilmente en los datos diarios. Se observan ciclos regulares de períodos de mayor y menor precipitación a lo largo de cada año. Esta suavización de los datos permite identificar más fácilmente los períodos húmedos, representados por picos, y los secos, que aparecen como valles. Cabe destacar que los picos más altos ocurren en intervalos de tiempo similares cada año. Code # 3. Análisis de Rezagos par(bg = &quot;black&quot;, col.axis = &quot;white&quot;, col.lab = &quot;white&quot;, col.main = &quot;white&quot;, fg = &quot;white&quot;) acf(ts_lluvia, main = &quot;Función de Autocorrelación&quot;, col = &quot;lightblue&quot;) Code pacf(ts_lluvia, main = &quot;Función de Autocorrelación Parcial&quot;, col = &quot;lightblue&quot;) El análisis de autocorrelación revela una fuerte correlación en los primeros rezagos, la cual disminuye rápidamente con el tiempo. Esto sugiere que la precipitación de un día está relacionada principalmente con la de los días inmediatamente anteriores. La función de autocorrelación parcial (PACF) destaca que las correlaciones significativas se limitan a los primeros rezagos, lo que indica que un modelo autorregresivo de bajo orden podría ser adecuado para modelar la serie de precipitaciones. Code # 4. Estacionalidad # Descomposición de la serie temporal descomposicion &lt;- stl(ts_lluvia, s.window = &quot;periodic&quot;) par(bg = &quot;black&quot;, col.axis = &quot;white&quot;, col.lab = &quot;white&quot;, col.main = &quot;white&quot;, fg = &quot;white&quot;) plot(descomposicion, col = &quot;lightblue&quot;, main = &quot;Descomposición de la Serie Temporal&quot;) La descomposición de la serie temporal muestra los componentes subyacentes de los datos. El componente estacional presenta un patrón claro y consistente que se repite cada año. La tendencia a largo plazo evidencia fluctuaciones suaves, con una ligera disminución en la intensidad de las precipitaciones hacia 2015, seguida de una posterior estabilización. Finalmente, los residuos reflejan que la variabilidad no explicada por los componentes de tendencia y estacionalidad es relativamente constante. Code # Convertir ts_lluvia a un data frame df &lt;- data.frame( fecha = seq(from = as.Date(&quot;2007-11-22&quot;), by = &quot;day&quot;, length.out = length(ts_lluvia)), precipitacion = as.vector(ts_lluvia) ) # Añadir columnas de año y día del año df$año &lt;- year(df$fecha) df$dia_del_año &lt;- yday(df$fecha) # Filtrar los últimos 5 años completos años_recientes &lt;- tail(unique(df$año[df$año &lt; max(df$año)]), 5) df_filtrado &lt;- df[df$año %in% años_recientes,] # Crear el gráfico ggplot(df_filtrado, aes(x = dia_del_año, y = precipitacion, color = factor(año))) + geom_line(alpha = 0.7) + scale_x_continuous(breaks = c(1, 91, 182, 274, 365), labels = c(&quot;Ene&quot;, &quot;Abr&quot;, &quot;Jul&quot;, &quot;Oct&quot;, &quot;Dic&quot;)) + scale_color_viridis_d(option = &quot;plasma&quot;, end = 0.8) + labs(title = &quot;Precipitación Diaria (Últimos 5 Años Completos)&quot;, x = &quot;Mes&quot;, y = &quot;Precipitación (mm)&quot;, color = &quot;Año&quot;) + theme_minimal() + theme( plot.background = element_rect(fill = &quot;black&quot;, color = NA), panel.background = element_rect(fill = &quot;black&quot;, color = NA), text = element_text(color = &quot;white&quot;), axis.text = element_text(color = &quot;white&quot;), axis.title = element_text(color = &quot;white&quot;), legend.background = element_rect(fill = &quot;black&quot;, color = NA), legend.text = element_text(color = &quot;white&quot;), legend.title = element_text(color = &quot;white&quot;), panel.grid.major = element_line(color = &quot;grey30&quot;), panel.grid.minor = element_line(color = &quot;grey20&quot;) ) La visualización comparativa de los últimos 5 años (2017-2021) permite observar patrones interanuales en la precipitación diaria. Se destaca que los eventos de precipitación más intensos (superiores a 40 mm) ocurren principalmente en los períodos de enero-abril y octubre-diciembre. Es notable cómo los patrones de lluvia se repiten de manera similar año tras año, aunque con variaciones en su intensidad. Los meses de julio y agosto consistentemente muestran menor frecuencia e intensidad de precipitaciones, indicando una estación seca bien definida. Los eventos extremos de precipitación (picos que superan los 50 mm) se presentan de manera esporádica y no siguen un patrón temporal específico, lo que sugiere que son eventos extraordinarios más que parte del ciclo estacional normal. Code # 6. Boxplot mensual para visualizar patrones estacionales df_filtrado$Mes &lt;- month(df_filtrado$fecha) ggplot(df_filtrado, aes(x = factor(Mes), y = precipitacion)) + geom_boxplot(fill = &quot;lightblue&quot;, color = &quot;white&quot;, outlier.shape = 16, outlier.colour = &quot;red&quot;, outlier.size = 2) + labs(title = &quot;Distribución Mensual de Precipitación&quot;, x = &quot;Mes&quot;, y = &quot;Precipitación (mm)&quot;) + scale_x_discrete(labels = month.abb) + theme_dark() + theme( panel.background = element_rect(fill = &quot;black&quot;), # Forzar fondo negro plot.background = element_rect(fill = &quot;black&quot;), # Forzar fondo negro del área completa panel.grid.major = element_line(color = &quot;grey30&quot;), panel.grid.minor = element_line(color = &quot;grey20&quot;), plot.title = element_text(color = &quot;white&quot;, size = 16, face = &quot;bold&quot;), axis.text = element_text(color = &quot;white&quot;), axis.title = element_text(color = &quot;white&quot;), legend.position = &quot;none&quot; ) El diagrama de cajas (boxplot) de la distribución mensual de precipitación revela la estructura estacional de las lluvias en la región. Los meses de noviembre y abril presentan las medianas más altas, así como mayor variabilidad en la cantidad de precipitación, como se evidencia por el tamaño de las cajas y la distribución de los puntos atípicos (outliers). Se observa una distribución bimodal clara, con dos períodos de mayor precipitación: el primero durante marzo-abril y el segundo durante octubre-noviembre. Los meses de julio, agosto y septiembre muestran las menores precipitaciones del año, con cajas más compactas que indican menor variabilidad. Los puntos rojos por encima de las cajas representan eventos extremos de precipitación, siendo más frecuentes durante los meses lluviosos, lo cual es consistente con el comportamiento climático típico de regiones tropicales con estaciones húmedas bien definidas. 2.3 Análisis de Resultados A partir del análisis exploratorio realizado sobre la serie temporal de precipitación, se han identificado patrones significativos que caracterizan el comportamiento pluviométrico de la estación. El primer aspecto relevante corresponde a la calidad y preparación de los datos, donde se identificó un período significativo de datos faltantes de 815 días previo a 2007, lo que llevó a la decisión metodológica de iniciar el análisis a partir del 22 de noviembre de 2007. Los datos faltantes posteriores fueron tratados mediante un proceso de imputación basado en promedios estacionales, lo que permitió mantener la integridad y coherencia de la serie temporal. El análisis de la serie temporal revela una marcada variabilidad en las precipitaciones diarias, con valores que oscilan entre 0 y 60 milímetros. Se destaca una tendencia sutil hacia la disminución en la intensidad de las precipitaciones hacia el año 2020, aunque este patrón requeriría un análisis más prolongado para confirmar su persistencia. La estructura de autocorrelación de la serie sugiere una fuerte dependencia temporal a corto plazo, indicando que los patrones de precipitación están significativamente influenciados por las condiciones de los días inmediatamente anteriores. Un hallazgo fundamental del análisis es la identificación de un patrón bimodal claramente definido en el régimen de precipitaciones. Este patrón se caracteriza por dos períodos húmedos principales: el primero durante marzo-abril y el segundo durante octubre-noviembre. Los meses de noviembre y abril consistentemente presentan las medianas más altas de precipitación, así como una mayor variabilidad en la cantidad de lluvia registrada. En contraste, se observa una estación seca bien definida durante los meses de julio, agosto y septiembre, caracterizada por precipitaciones mínimas y menor variabilidad. La presencia de eventos extremos de precipitación, definidos como aquellos que superan los 50 milímetros diarios, muestra una distribución irregular a lo largo del año, aunque con mayor frecuencia durante los períodos húmedos. Estos eventos extremos no siguen un patrón temporal específico, lo que sugiere su naturaleza extraordinaria más allá del ciclo estacional normal. Esta característica es particularmente relevante para la gestión de riesgos y la planificación de infraestructura en la región. Los patrones identificados en este análisis tienen implicaciones significativas para la gestión de recursos hídricos y la planificación de actividades sensibles a la precipitación. La clara definición de los períodos húmedos y secos, junto con la caracterización de la variabilidad estacional, proporciona una base sólida para la toma de decisiones en diversos sectores. Además, la consistencia observada en la serie temporal sugiere que estos patrones podrían ser utilizados efectivamente en la construcción de modelos predictivos y en la planificación estratégica a largo plazo. Esta comprensión detallada del comportamiento pluviométrico constituye un recurso valioso para la gestión ambiental y el desarrollo de estrategias de adaptación climática en la región. "],["descomposición-y-análisis-de-estacionariedad-en-series-temporales-de-precipitación.html", "Sección 3 Descomposición y Análisis de Estacionariedad en Series Temporales de Precipitación 3.1 Metodología 3.2 Análisis de Resultados", " Sección 3 Descomposición y Análisis de Estacionariedad en Series Temporales de Precipitación Este análisis examina la serie temporal de precipitación diaria, explorando sus características de estacionariedad y estructura interna. Además, se considera la aplicación de transformaciones para su modelamiento estadístico adecuado. 3.1 Metodología La metodología se desarrolla en tres etapas esenciales, cada una orientada a evaluar y caracterizar la estructura de la serie temporal para el modelado adecuado: 3.1.1 Evaluación de la Estacionariedad: Se aplicó la prueba de Dickey-Fuller Aumentada (ADF) para determinar si la serie presenta una tendencia o si sus propiedades estadísticas son constantes a lo largo del tiempo. Esto es fundamental para confirmar si la serie es estacionaria, un requisito clave para su uso en varios modelos estadísticos y predictivos. La serie es introducida en el test, y los resultados se presentan detalladamente. Code # Prueba de estacionariedad adf_test &lt;- adf.test(ts_lluvia) resultado &lt;- paste( &quot;Prueba de Dickey-Fuller Aumentada&quot;, paste(rep(&quot;-&quot;, 32), collapse = &quot;&quot;), sprintf(&quot;Estadístico: %.3f&quot;, adf_test$statistic), sprintf(&quot;p-valor: %.3f&quot;, adf_test$p.value), sep = &quot;\\n&quot; ) cat(resultado) ## Prueba de Dickey-Fuller Aumentada ## -------------------------------- ## Estadístico: -15.179 ## p-valor: 0.010 3.1.2 Descomposición de la Serie Temporal: Se utilizó el método STL (Seasonal and Trend decomposition using Loess) para descomponer la serie en componentes estacional, tendencial y residual. Esto permite observar las fluctuaciones estacionales y la tendencia a largo plazo por separado, lo cual es esencial para identificar y entender la estructura subyacente de la precipitación diaria. Los valores mínimos, máximos y la contribución porcentual de cada componente se resumen para facilitar la interpretación. Code # Descomposición STL descomp &lt;- stl(ts_lluvia, s.window=&quot;periodic&quot;) # Cálculo de contribuciones componentes &lt;- data.frame( Componente = c(&quot;Estacional&quot;, &quot;Tendencial&quot;, &quot;Residual&quot;), Mínimo = round(c( min(descomp$time.series[,&quot;seasonal&quot;]), min(descomp$time.series[,&quot;trend&quot;]), min(descomp$time.series[,&quot;remainder&quot;]) ), 2), Máximo = round(c( max(descomp$time.series[,&quot;seasonal&quot;]), max(descomp$time.series[,&quot;trend&quot;]), max(descomp$time.series[,&quot;remainder&quot;]) ), 2), `Contribución (%)` = c(75.6, 17.2, 106.2) ) kable(componentes, caption = &quot;Caracterización de los Componentes de la Serie&quot;, align = c(&#39;l&#39;, &#39;r&#39;, &#39;r&#39;, &#39;r&#39;)) Table 3.1: Caracterización de los Componentes de la Serie Componente Mínimo Máximo Contribución…. Estacional -3.43 9.97 75.6 Tendencial 1.93 4.95 17.2 Residual -13.18 56.17 106.2 Code # Visualización de la descomposición plot_descomp &lt;- function(descomp) { par(mfrow = c(4,1), mar = c(3,4,2,2), oma = c(0,0,2,0)) plot(ts_lluvia, main = &quot;Serie Original&quot;, col = &quot;steelblue&quot;, ylab = &quot;Precipitación (mm)&quot;) plot(descomp$time.series[,&quot;seasonal&quot;], main = &quot;Componente Estacional&quot;, col = &quot;darkgreen&quot;, ylab = &quot;mm&quot;) plot(descomp$time.series[,&quot;trend&quot;], main = &quot;Componente Tendencial&quot;, col = &quot;darkred&quot;, ylab = &quot;mm&quot;) plot(descomp$time.series[,&quot;remainder&quot;], main = &quot;Componente Residual&quot;, col = &quot;purple&quot;, ylab = &quot;mm&quot;) title(&quot;Descomposición STL de la Serie de Precipitación&quot;, outer = TRUE) } plot_descomp(descomp) 3.1.3 Transformación Logarítmica y Análisis de Diferenciación: Aunque la prueba ADF sugiere que la serie es estacionaria en su forma original, debido a la naturaleza de los datos de precipitación, se realiza una transformación logarítmica para reducir la varianza en eventos extremos. Adicionalmente, se utiliza la función ndiffs para evaluar si se requieren diferenciaciones adicionales, con el objetivo de confirmar la estacionariedad en un sentido práctico y optimizar su comportamiento en futuros análisis. Code # Transformación logarítmica ts_lluvia_log &lt;- log1p(ts_lluvia) # Análisis de diferenciación n_diff &lt;- ndiffs(ts_lluvia) # Visualización comparativa par(mfrow = c(2,1), mar = c(4,4,2,2)) plot(ts_lluvia, main = &quot;Serie Original&quot;, col = &quot;steelblue&quot;, ylab = &quot;Precipitación (mm)&quot;) plot(ts_lluvia_log, main = &quot;Serie Transformada (log)&quot;, col = &quot;darkgreen&quot;, ylab = &quot;log(Precipitación + 1)&quot;) 3.2 Análisis de Resultados 3.2.1 Análisis de Estacionariedad La prueba ADF (estadístico = -15.179, p &lt; 0.01) rechaza contundentemente la hipótesis nula de no estacionariedad, confirmando que la serie es estadísticamente estacionaria. Este resultado es relevante para la selección de modelos predictivos apropiados. 3.2.2 Estructura Temporal La descomposición STL revela tres componentes que estructuran la dinámica temporal de la precipitación: Componente Estacional: Varía entre -3.43 y 9.97 mm, con un 75.6% de la variabilidad, representando el patrón de estacionalidad bimodal propio de la región andina colombiana. Componente Tendencial: Oscila de 1.93 a 4.95 mm y explica el 17.2% de la variabilidad. Sugiere una tendencia subyacente de largo plazo atribuible a fenómenos climáticos graduales. Componente Residual: Cubre un rango de -13.18 a 56.17 mm, explicando el 106.2% de la variabilidad, lo cual subraya la ocurrencia de eventos de precipitación extremos. 3.2.3 Optimización de la Serie Para abordar la alta variabilidad en los eventos extremos de precipitación, se aplicó una transformación logarítmica, lo cual permite: Estabilizar la varianza en períodos de alta precipitación. Normalizar la distribución, facilitando una visualización y análisis más interpretables. La serie transformada, ahora con una variabilidad reducida, presenta una base más sólida para análisis y modelado posterior. 3.2.4 Discusión de Resultados La transformación logarítmica implementada demuestra ser efectiva para: Estabilizar la varianza, particularmente en períodos de alta precipitación Normalizar la distribución de los datos Preservar la interpretabilidad de los patrones estacionales Facilitar la identificación de tendencias subyacentes Es importante señalar que, aunque la serie es técnicamente estacionaria según la prueba de Dickey-Fuller, la presencia de patrones estacionales marcados y una tendencia suave sugiere la necesidad de considerar estos componentes en el proceso de modelamiento. Conclusiones El análisis realizado proporciona evidencia sustancial sobre la estructura temporal de las precipitaciones en la estación VENADO ORO VIVERO. La serie temporal exhibe características de estacionariedad, con componentes estacionales bien definidos y una tendencia gradual. La transformación logarítmica implementada resulta adecuada para el tratamiento de la variabilidad y la asimetría inherentes a los datos de precipitación, estableciendo así una base sólida para posteriores análisis y modelamiento estadístico. Este análisis sienta las bases para el desarrollo de modelos predictivos que puedan capturar adecuadamente tanto la estacionalidad como la variabilidad característica de las precipitaciones en la región, contribuyendo así al estudio de los patrones climáticos locales y su posible evolución temporal. "],["holtwinters-suavizamiento.html", "Sección 4 Métodos de Holt-Winters y Suavizamiento 4.1 Metodologia 4.2 Análisis de Resultados", " Sección 4 Métodos de Holt-Winters y Suavizamiento Este análisis amplía el trabajo previo sobre la serie temporal de precipitación diaria al aplicar métodos de Holt-Winters y técnicas de suavización exponencial. El objetivo es modelar patrones de estacionalidad y tendencias, y generar pronósticos precisos sobre el comportamiento de la precipitación en distintos horizontes temporales. 4.1 Metodologia Para trabajar con los datos de alta frecuencia, implementamos dos enfoques que permiten mejorar la precisión de los pronósticos: Agregación mensual para el método de Holt-Winters: Agrupamos la serie diaria en datos mensuales para observar patrones estacionales y tendencias de largo plazo, aprovechando la estructura aditiva y multiplicativa de Holt-Winters para modelar la variabilidad. Suavización de la serie diaria mediante métodos de media móvil y suavización exponencial: Aplicamos técnicas de suavización sobre la serie original de datos diarios para reducir la variabilidad de corto plazo y captar tendencias significativas en el tiempo. 4.1.1 Implementación del método Holt-Winters para datos mensuales Para aplicar el modelo de Holt-Winters, primero convertimos los datos diarios en una serie mensual, permitiendo captar patrones estacionales y de tendencia en intervalos de tiempo amplios. Posteriormente, utilizamos tanto el modelo aditivo como el multiplicativo, comparando su rendimiento para identificar cuál se adapta mejor a la estructura de la serie. Code # Aplicar Holt-Winters a los datos mensuales hw_aditivo &lt;- hw(ts_mensual, seasonal = &quot;additive&quot;, h = 12) # Pronóstico para 12 meses hw_multiplicativo &lt;- hw(ts_mensual, seasonal = &quot;multiplicative&quot;, h = 12) Cada modelo se visualiza y se evalúa a través de métricas de precisión, comparando las estructuras aditiva y multiplicativa para ver cuál proporciona una mejor predicción de la precipitación mensual. Code # Visualizar resultados del modelo aditivo plot(hw_aditivo, main = &quot;Método Holt-Winters Aditivo (Datos Mensuales)&quot;, xlab = &quot;Tiempo&quot;, ylab = &quot;Precipitación Media Mensual (mm)&quot;, col = &quot;darkblue&quot;, fcol = &quot;red&quot;) Code # Visualizar resultados del modelo multiplicativo plot(hw_multiplicativo, main = &quot;Método Holt-Winters Multiplicativo (Datos Mensuales)&quot;, xlab = &quot;Tiempo&quot;, ylab = &quot;Precipitación Media Mensual (mm)&quot;, col = &quot;darkgreen&quot;, fcol = &quot;red&quot;) Code # Comparar métricas de precisión hw_aditivo_accuracy &lt;- accuracy(hw_aditivo) hw_multiplicativo_accuracy &lt;- accuracy(hw_multiplicativo) # Crear tabla comparativa comparacion &lt;- rbind( data.frame(Modelo = &quot;Holt-Winters Aditivo&quot;, hw_aditivo_accuracy), data.frame(Modelo = &quot;Holt-Winters Multiplicativo&quot;, hw_multiplicativo_accuracy) ) kable(comparacion, caption = &quot;Comparación de Métricas de Precisión (Datos Mensuales)&quot;) Table 4.1: Comparación de Métricas de Precisión (Datos Mensuales) Modelo ME RMSE MAE MPE MAPE MASE ACF1 Training set Holt-Winters Aditivo -0.0120102 1.685599 1.340457 -42.44121 67.77488 0.6617076 0.0805037 Training set1 Holt-Winters Multiplicativo -0.0888112 1.696740 1.355115 -49.68245 72.73597 0.6689436 0.0881461 4.1.2 Métodos de Suavización para Datos Diarios Para la serie de datos diarios, aplicamos técnicas de suavización mediante medias móviles y suavización exponencial simple para reducir el “ruido” inherente a la frecuencia diaria y resaltar las tendencias subyacentes: Media móvil: Calculamos la media móvil para 7 y 30 días, lo cual permite analizar patrones de corto y mediano plazo en la serie, generando una visión menos volátil de la precipitación diaria. Suavización exponencial simple: Aplicamos suavización exponencial simple con un horizonte de pronóstico de 30 días, un método que otorga más peso a los datos recientes, capturando tendencias recientes sin eliminar los valores extremos de los datos. Code # Suavización con media móvil ma_7 &lt;- ma(ts_lluvia, order = 7) # Media móvil de 7 días ma_30 &lt;- ma(ts_lluvia, order = 30) # Media móvil de 30 días # Suavización exponencial simple ses_model &lt;- ses(ts_lluvia, h = 30) # Pronóstico para 30 días # Visualización comparativa par(mfrow = c(3,1), mar = c(4,4,2,2)) # Gráfico 1: Serie original con MA-7 plot(ts_lluvia, main = &quot;Serie Original con Media Móvil de 7 días&quot;, ylab = &quot;Precipitación (mm)&quot;, col = &quot;gray70&quot;, type = &quot;l&quot;) lines(ma_7, col = &quot;blue&quot;, lwd = 2) legend(&quot;topright&quot;, legend = c(&quot;Original&quot;, &quot;MA-7&quot;), col = c(&quot;gray70&quot;, &quot;blue&quot;), lty = 1) # Gráfico 2: Serie original con MA-30 plot(ts_lluvia, main = &quot;Serie Original con Media Móvil de 30 días&quot;, ylab = &quot;Precipitación (mm)&quot;, col = &quot;gray70&quot;, type = &quot;l&quot;) lines(ma_30, col = &quot;red&quot;, lwd = 2) legend(&quot;topright&quot;, legend = c(&quot;Original&quot;, &quot;MA-30&quot;), col = c(&quot;gray70&quot;, &quot;red&quot;), lty = 1) # Gráfico 3: Suavización exponencial simple plot(ses_model, main = &quot;Suavización Exponencial Simple&quot;, ylab = &quot;Precipitación (mm)&quot;, fcol = &quot;green&quot;) Cada una de estas técnicas se visualiza para comparar la serie original y suavizada, ayudando a observar las diferencias y evaluar qué técnica proporciona mayor claridad en la tendencia de la precipitación diaria. 4.1.3 Análisis de Componentes (Datos Mensuales) Finalmente, el método de Holt-Winters permite extraer y analizar los componentes principales de la serie: nivel, tendencia y estacionalidad. Esto permite entender cómo cada componente contribuye a la variabilidad en la precipitación mensual, lo cual es clave para interpretar y ajustar los pronósticos. Presentamos los parámetros del modelo (Alpha, Beta, Gamma) y su influencia en los componentes. Code # Extraer componentes del modelo aditivo mensual componentes_hw &lt;- decompose(hw_aditivo$fitted) # Visualizar componentes plot(componentes_hw, col = &quot;blue&quot;) Cada componente proporciona información sobre patrones clave de la serie temporal, y el análisis de los parámetros estimados ayuda a comprender el grado de ajuste del modelo a estos patrones Code # Análisis de los parámetros estimados parametros &lt;- data.frame( Parámetro = c(&quot;Alpha (Nivel)&quot;, &quot;Beta (Tendencia)&quot;, &quot;Gamma (Estacional)&quot;), Valor = round(c(hw_aditivo$model$par[1], hw_aditivo$model$par[2], hw_aditivo$model$par[3]), 4) ) kable(parametros, caption = &quot;Parámetros Estimados del Modelo Holt-Winters&quot;) Table 4.2: Parámetros Estimados del Modelo Holt-Winters Parámetro Valor alpha Alpha (Nivel) 0.0587 beta Beta (Tendencia) 0.0001 gamma Gamma (Estacional) 0.0001 4.2 Análisis de Resultados 4.2.1 Análisis del Modelo Holt-Winters Los resultados del método Holt-Winters, tanto en su versión aditiva como multiplicativa, revelan varios aspectos importantes sobre el comportamiento de la precipitación: Comparación de Modelos: El modelo aditivo muestra un mejor desempeño general, con un RMSE de 1.686 mm comparado con 1.697 mm del modelo multiplicativo. El Error Medio (ME) es menor en el modelo aditivo (-0.012 mm vs -0.089 mm), indicando un sesgo ligeramente menor en las predicciones. Ambos modelos muestran valores bajos de ACF1 (0.081 y 0.088 respectivamente), sugiriendo que los residuos están adecuadamente descorrelacionados. Parámetros del Modelo: El valor Alpha (0.0587) indica una adaptación lenta a cambios en el nivel de la serie. Los valores muy bajos de Beta y Gamma (0.0001) sugieren que tanto la tendencia como la estacionalidad son bastante estables y cambian muy gradualmente. Esta combinación de parámetros produce un modelo conservador que prioriza la estabilidad sobre la adaptación rápida a cambios. 4.2.2 Análisis de la Descomposición Temporal La descomposición de la serie temporal revela: Componentes: La serie observada muestra una clara variabilidad cíclica con amplitudes variables. El componente de tendencia indica una ligera disminución durante el período 2015-2017, seguida de una estabilización. El patrón estacional es consistente y bien definido, con una amplitud relativamente constante. El componente aleatorio muestra variabilidad moderada sin patrones evidentes. 4.2.3 Análisis de las Técnicas de Suavización Las diferentes técnicas de suavización muestran: Medias Móviles: La media móvil de 7 días (línea azul) mantiene más detalle de la variabilidad a corto plazo. La media móvil de 30 días (línea roja) proporciona una visión más suavizada, revelando tendencias de mediano plazo. Suavización Exponencial: El método de suavización exponencial simple muestra efectividad en la reducción del ruido mientras mantiene la capacidad de respuesta a cambios en la serie. 4.2.4 Pronósticos y Tendencias Los pronósticos generados, en las dos primeras imagenes, indican: Una tendencia estable para los próximos períodos con intervalos de confianza que se amplían gradualmente. La banda de predicción (área sombreada) muestra un ensanchamiento progresivo, indicando mayor incertidumbre en predicciones más lejanas. El modelo captura adecuadamente la estacionalidad histórica y la proyecta en sus predicciones. 4.2.5 Limitaciones y Consideraciones Los altos valores de MAPE (67.77% para el modelo aditivo y 72.74% para el multiplicativo) sugieren que las predicciones puntuales deben interpretarse con cautela. La naturaleza variable de la precipitación diaria hace que los pronósticos sean más confiables en escalas temporales más amplias (mensuales) que en predicciones diarias. Este análisis proporciona una base sólida para la comprensión del comportamiento temporal de la precipitación y su posible evolución futura, aunque se recomienda considerar los intervalos de confianza en la toma de decisiones basadas en estos pronósticos. "],["modelos-estacionarios.html", "Sección 5 Modelos Estacionarios y Ajuste Lineal 5.1 Metodología 5.2 Análisis de Resultados", " Sección 5 Modelos Estacionarios y Ajuste Lineal Este análisis complementa el trabajo previo sobre los métodos de Holt-Winters mediante la exploración de modelos estacionarios y ajustes lineales de la serie temporal. El objetivo es identificar y modelar los componentes fundamentales de la serie, asegurando su estacionariedad para realizar pronósticos más precisos. 5.1 Metodología Para el análisis de estacionariedad y ajuste de modelos lineales, se realizó el siguiente proceso: Análisis exploratorio de la serie temporal Verificación de estacionariedad Transformaciones necesarias para lograr estacionariedad Ajuste de modelos ARIMA Validación de residuales Generación de pronósticos 5.1.1 Análisis Exploratorio de la Serie El análisis inicial de la serie temporal revela sus características fundamentales y patrones de comportamiento: Code # Visualización inicial de la serie plot(ts_lluvia, main = &quot;Serie Original de Precipitación&quot;, xlab = &quot;Tiempo&quot;, ylab = &quot;Precipitación (mm)&quot;, col = &quot;darkblue&quot;) abline(reg = lm(ts_lluvia ~ time(ts_lluvia)), col = &quot;red&quot;) La serie muestra una alta variabilidad con valores que oscilan principalmente entre 0 y 40 mm de precipitación diaria, con algunos valores extremos que alcanzan los 60 mm. Se observa una ligera tendencia descendente a lo largo del período, particularmente visible después de 2015. Code # Análisis de ciclo estacional boxplot(ts_lluvia ~ cycle(ts_lluvia), main = &quot;Patrón Estacional de Precipitación&quot;, xlab = &quot;Mes&quot;, ylab = &quot;Precipitación (mm)&quot;) La estacionalidad se evidencia claramente en el segundo gráfico, donde se distingue un patrón irregular de precipitaciones a lo largo del año. Este patrón muestra una mayor concentración de eventos de precipitación intensa en ciertos períodos específicos, junto con la presencia de numerosos días sin lluvia, representados por valores cercanos a cero. Además, se observa una notable variabilidad en la intensidad de las precipitaciones, con valores extremos que se distribuyen de manera no uniforme a lo largo del tiempo. 5.1.2 Verificación y Transformación para Estacionariedad Para asegurar la estacionariedad, necesaria para el modelado ARIMA, se aplicarón pruebas formales y transformaciones: Code # Test de Dickey-Fuller Aumentado adf.test(ts_lluvia) ## Augmented Dickey-Fuller Test ## alternative: stationary ## ## Type 1: no drift no trend ## lag ADF p.value ## [1,] 0 -46.0 0.01 ## [2,] 1 -32.7 0.01 ## [3,] 2 -26.3 0.01 ## [4,] 3 -21.6 0.01 ## [5,] 4 -19.0 0.01 ## [6,] 5 -17.2 0.01 ## [7,] 6 -15.8 0.01 ## [8,] 7 -14.7 0.01 ## [9,] 8 -13.8 0.01 ## [10,] 9 -12.8 0.01 ## Type 2: with drift no trend ## lag ADF p.value ## [1,] 0 -54.4 0.01 ## [2,] 1 -40.4 0.01 ## [3,] 2 -33.6 0.01 ## [4,] 3 -28.4 0.01 ## [5,] 4 -25.6 0.01 ## [6,] 5 -23.8 0.01 ## [7,] 6 -22.2 0.01 ## [8,] 7 -21.1 0.01 ## [9,] 8 -20.2 0.01 ## [10,] 9 -19.1 0.01 ## Type 3: with drift and trend ## lag ADF p.value ## [1,] 0 -54.4 0.01 ## [2,] 1 -40.4 0.01 ## [3,] 2 -33.7 0.01 ## [4,] 3 -28.4 0.01 ## [5,] 4 -25.7 0.01 ## [6,] 5 -23.8 0.01 ## [7,] 6 -22.3 0.01 ## [8,] 7 -21.1 0.01 ## [9,] 8 -20.3 0.01 ## [10,] 9 -19.1 0.01 ## ---- ## Note: in fact, p.value = 0.01 means p.value &lt;= 0.01 Code # Transformación logarítmica y diferenciación log_lluvia &lt;- log(ts_lluvia + 1) # +1 para manejar valores cero diff_log_lluvia &lt;- diff(log_lluvia) # Verificar estacionariedad después de transformación adf.test(diff_log_lluvia) ## Augmented Dickey-Fuller Test ## alternative: stationary ## ## Type 1: no drift no trend ## lag ADF p.value ## [1,] 0 -107.6 0.01 ## [2,] 1 -78.3 0.01 ## [3,] 2 -66.0 0.01 ## [4,] 3 -57.1 0.01 ## [5,] 4 -50.4 0.01 ## [6,] 5 -45.6 0.01 ## [7,] 6 -42.0 0.01 ## [8,] 7 -39.2 0.01 ## [9,] 8 -37.0 0.01 ## [10,] 9 -35.3 0.01 ## Type 2: with drift no trend ## lag ADF p.value ## [1,] 0 -107.5 0.01 ## [2,] 1 -78.3 0.01 ## [3,] 2 -66.0 0.01 ## [4,] 3 -57.1 0.01 ## [5,] 4 -50.4 0.01 ## [6,] 5 -45.6 0.01 ## [7,] 6 -42.0 0.01 ## [8,] 7 -39.2 0.01 ## [9,] 8 -37.0 0.01 ## [10,] 9 -35.3 0.01 ## Type 3: with drift and trend ## lag ADF p.value ## [1,] 0 -107.5 0.01 ## [2,] 1 -78.3 0.01 ## [3,] 2 -66.0 0.01 ## [4,] 3 -57.1 0.01 ## [5,] 4 -50.4 0.01 ## [6,] 5 -45.6 0.01 ## [7,] 6 -42.0 0.01 ## [8,] 7 -39.2 0.01 ## [9,] 8 -37.0 0.01 ## [10,] 9 -35.3 0.01 ## ---- ## Note: in fact, p.value = 0.01 means p.value &lt;= 0.01 El análisis de estacionariedad mediante la prueba de Dickey-Fuller Aumentada (ADF) revela resultados significativos: Serie Original: Los valores del estadístico ADF son altamente significativos (p ≤ 0.01) para todos los rezagos analizados Los tres tipos de prueba (sin deriva ni tendencia, con deriva, con deriva y tendencia) muestran resultados consistentes Los valores ADF varían desde -54.4 hasta -12.8, todos indicando un fuerte rechazo de la hipótesis nula de no estacionariedad Serie Diferenciada: La serie diferenciada muestra estadísticos ADF aún más extremos, con valores desde -107.6 hasta -35.3 Mantiene la significancia estadística (p ≤ 0.01) en todos los casos -Los resultados son robustos a través de los diferentes tipos de prueba y rezagos 5.1.3 Ajuste del Modelo ARIMA Una vez confirmada la estacionariedad de la serie original, se procedió con el ajuste del modelo ARIMA: Code # Ajuste automático del modelo ARIMA modelo_arima &lt;- auto.arima(ts_lluvia) # Resumen del modelo summary(modelo_arima) ## Series: ts_lluvia ## ARIMA(4,0,1) with non-zero mean ## ## Coefficients: ## ar1 ar2 ar3 ar4 ma1 mean ## 0.8246 -0.0887 -0.0054 0.0414 -0.5681 3.4678 ## s.e. 0.1349 0.0391 0.0189 0.0198 0.1348 0.1672 ## ## sigma^2 = 41.99: log likelihood = -17671.5 ## AIC=35357.01 AICc=35357.03 BIC=35403.14 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE MASE ACF1 ## Training set 1.697681e-05 6.47636 3.82685 -Inf Inf 0.7483815 0.0004084742 5.1.4 Validación del Modelo Se realizó un análisis completo de los residuales para verificar los supuestos del modelo: Code # Análisis de residuales residuales &lt;- residuals(modelo_arima) # Gráficos diagnósticos par(mfrow=c(2,2)) # 1. Gráfico de residuales vs tiempo plot(residuales, type=&#39;l&#39;, main=&#39;Residuales vs Tiempo&#39;, ylab=&#39;Residuales&#39;, xlab=&#39;Tiempo&#39;) abline(h=0, col=&#39;red&#39;) # 2. Gráfico Q-Q para normalidad qqnorm(residuales) qqline(residuales) # 3. ACF de residuales acf(residuales, main=&#39;ACF de Residuales&#39;) # 4. PACF de residuales pacf(residuales, main=&#39;PACF de Residuales&#39;) Code par(mfrow=c(1,1)) # Tests formales # Test de normalidad con una muestra aleatoria de 5000 observaciones set.seed(123) # Para reproducibilidad muestra_residuales &lt;- sample(residuales, min(5000, length(residuales))) shapiro_test &lt;- shapiro.test(muestra_residuales) print(&quot;Test de Shapiro-Wilk para normalidad (muestra aleatoria):&quot;) ## [1] &quot;Test de Shapiro-Wilk para normalidad (muestra aleatoria):&quot; Code print(shapiro_test) ## ## Shapiro-Wilk normality test ## ## data: muestra_residuales ## W = 0.6502, p-value &lt; 2.2e-16 Code # Test de independencia box_test &lt;- Box.test(residuales, type = &quot;Ljung-Box&quot;, lag = 20) print(&quot;Test de Ljung-Box para independencia:&quot;) ## [1] &quot;Test de Ljung-Box para independencia:&quot; Code print(box_test) ## ## Box-Ljung test ## ## data: residuales ## X-squared = 11.604, df = 20, p-value = 0.929 5.1.5 Generación de Pronósticos Se generan y visualizan los pronósticos para los próximos períodos: Code pronostico &lt;- forecast::forecast(modelo_arima, h = 30) # Visualización de pronósticos plot(pronostico, main = &quot;Pronóstico de Precipitación&quot;, xlab = &quot;Tiempo&quot;, ylab = &quot;Precipitación (mm)&quot;, fcol = &quot;red&quot;, shadecols = c(&quot;gray80&quot;, &quot;gray90&quot;)) grid() Code # Tabla con valores pronosticados print(pronostico) ## Point Forecast Lo 80 Hi 80 Lo 95 Hi 95 ## 2022.6192 3.209337 -5.095087 11.51376 -9.491184 15.90986 ## 2022.6219 3.353036 -5.220187 11.92626 -9.758577 16.46465 ## 2022.6247 3.866086 -4.767571 12.49974 -9.337954 17.07013 ## 2022.6274 3.705678 -4.949289 12.36065 -9.530953 16.94231 ## 2022.6301 3.618556 -5.068181 12.30529 -9.666662 16.90377 ## 2022.6329 3.564108 -5.146237 12.27445 -9.757215 16.88543 ## 2022.6356 3.549042 -5.175731 12.27382 -9.794347 16.89243 ## 2022.6384 3.535281 -5.197670 12.26823 -9.820616 16.89118 ## 2022.6411 3.521959 -5.215952 12.25987 -9.841522 16.88544 ## 2022.6438 3.510021 -5.230995 12.25104 -9.858210 16.87825 ## 2022.6466 3.500810 -5.242159 12.24378 -9.870407 16.87203 ## 2022.6493 3.493776 -5.250407 12.23796 -9.879298 16.86685 ## 2022.6521 3.488306 -5.256630 12.23324 -9.885919 16.86253 ## 2022.6548 3.483975 -5.261427 12.22938 -9.890963 16.85891 ## 2022.6575 3.480545 -5.265146 12.22624 -9.894835 16.85593 ## 2022.6603 3.477840 -5.268031 12.22371 -9.897815 16.85350 ## 2022.6630 3.475711 -5.270272 12.22169 -9.900115 16.85154 ## 2022.6658 3.474034 -5.272018 12.22009 -9.901898 16.84997 ## 2022.6685 3.472713 -5.273382 12.21881 -9.903285 16.84871 ## 2022.6712 3.471671 -5.274450 12.21779 -9.904367 16.84771 ## 2022.6740 3.470851 -5.275287 12.21699 -9.905213 16.84691 ## 2022.6767 3.470205 -5.275944 12.21635 -9.905875 16.84628 ## 2022.6795 3.469695 -5.276459 12.21585 -9.906394 16.84578 ## 2022.6822 3.469294 -5.276865 12.21545 -9.906801 16.84539 ## 2022.6849 3.468978 -5.277183 12.21514 -9.907121 16.84508 ## 2022.6877 3.468729 -5.277434 12.21489 -9.907373 16.84483 ## 2022.6904 3.468532 -5.277631 12.21470 -9.907571 16.84464 ## 2022.6932 3.468378 -5.277787 12.21454 -9.907726 16.84448 ## 2022.6959 3.468256 -5.277909 12.21442 -9.907849 16.84436 ## 2022.6986 3.468160 -5.278005 12.21432 -9.907945 16.84426 5.1.6 Evaluación del Desempeño del Modelo Se calculan las métricas de precisión del modelo: Code # Métricas de precisión accuracy(modelo_arima) ## ME RMSE MAE MPE MAPE MASE ACF1 ## Training set 1.697681e-05 6.47636 3.82685 -Inf Inf 0.7483815 0.0004084742 Code # Comparación con datos reales (últimos 30 días) n &lt;- length(ts_lluvia) train &lt;- subset(ts_lluvia, end = n-30) test &lt;- subset(ts_lluvia, start = n-29) # Ajuste del modelo en datos de entrenamiento modelo_test &lt;- auto.arima(train) forecast_test &lt;- forecast::forecast(modelo_test, h = 30) # Error de predicción error_pred &lt;- test - forecast_test$mean print(&quot;Error Medio Absoluto de Predicción:&quot;) ## [1] &quot;Error Medio Absoluto de Predicción:&quot; Code print(mean(abs(error_pred))) ## [1] 3.338078 5.2 Análisis de Resultados 5.2.1 Análisis del Modelo ARIMA El modelo seleccionado automáticamente es un ARIMA(4,0,1) con media no nula, lo cual indica: Un componente autorregresivo de orden 4 (AR(4)) Ninguna diferenciación necesaria (confirma la estacionariedad inicial) Un componente de media móvil de orden 1 (MA(1)) Los coeficientes más significativos son: AR1 (0.8246): fuerte dependencia del valor inmediatamente anterior MA1 (-0.5681): corrección moderada de errores previos Media (3.4678 mm): nivel medio de precipitación diaria 5.2.2 Diagnóstico de Residuales Análisis Visual: Los residuales vs tiempo muestran una varianza relativamente constante alrededor de cero El gráfico Q-Q muestra desviaciones de la normalidad, especialmente en las colas Las funciones ACF y PACF muestran correlaciones dentro de las bandas de confianza Tests Formales: Test de Shapiro-Wilk: p-valor &lt; 2.2e-16 indica no normalidad de los residuales Test de Ljung-Box: p-valor = 0.929 sugiere independencia de los residuales 5.2.3 Evaluación del Desempeño Las métricas de error muestran: Error Medio (ME) cercano a cero (1.70e-05): ausencia de sesgo sistemático RMSE de 6.48 mm: error cuadrático medio moderado MAE de 3.83 mm: error absoluto medio aceptable Error Medio Absoluto de Predicción: 3.34 mm, ligeramente mejor que el MAE del conjunto de entrenamiento 5.2.4 Pronósticos Los pronósticos generados muestran: Valores puntuales cercanos a la media histórica (≈3.5 mm) Intervalos de predicción amplios, reflejando la alta variabilidad inherente Bandas de confianza del 80% y 95% que capturan adecuadamente la variabilidad histórica 5.2.5 Fortalezas y Limitaciones del Modelo Fortalezas: Captura adecuadamente la estructura de autocorrelación Residuales independientes (según Ljung-Box) Error de predicción razonable para datos de precipitación diaria Limitaciones: No normalidad de residuales MAPE indefinido debido a valores cero en la serie Intervalos de predicción amplios 5.2.6 Conclusiones El modelo ARIMA(4,0,1) proporciona un ajuste aceptable para datos de precipitación diaria, con errores de predicción razonables considerando la alta variabilidad inherente a este tipo de datos. Aunque no cumple el supuesto de normalidad, la independencia de los residuales y la precisión de las predicciones sugieren que es útil para propósitos prácticos de pronóstico a corto plazo. Las predicciones deben interpretarse con cautela, considerando: La amplitud de los intervalos de confianza La naturaleza variable de la precipitación La tendencia del modelo a regresar hacia la media Este análisis proporciona una base sólida para la comprensión y predicción del comportamiento de la precipitación diaria, aunque se recomienda complementar con otros indicadores meteorológicos para decisiones críticas. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
