[["index.html", "Análisis de Series Temporales de Lluvia: Estación VENADO ORO VIVERO [21205580] Sección 1 Importancia del Análisis de la Precipitación", " Análisis de Series Temporales de Lluvia: Estación VENADO ORO VIVERO [21205580] Dónoban Rojas Sección 1 Importancia del Análisis de la Precipitación Se propone el análisis de los datos de precipitación diaria registrados en la estación climatológica “VENADO ORO VIVERO”, ubicada en Bogotá, con coordenadas 4.60° de latitud y -74.06° de longitud, y una altitud de 2,725 metros sobre el nivel del mar. Esta estación, parte de la red del Instituto de Hidrología, Meteorología y Estudios Ambientales (IDEAM), cuenta con datos históricos desde el 1 de agosto de 1965 hasta el 10 de agosto de 2022. La variable seleccionada es la precipitación diaria (PTPM_CON), medida en milímetros (mm). Justificación del uso de datos de precipitación El análisis de las series temporales de precipitación es fundamental para comprender las características climáticas locales y su evolución a lo largo del tiempo. Este tipo de estudio permite identificar patrones estacionales, tendencias a largo plazo y fenómenos extremos, aspectos cruciales para pronosticar eventos climáticos relevantes. La estación VENADO ORO VIVERO ha sido seleccionada por su accesibilidad de datos y su cercanía a la Pontificia Universidad Javeriana sede Bogotá, donde actualmente se lleva a cabo una investigación aplicada sobre Sistemas Urbanos de Drenaje Sostenible (SuDS) en el contexto del cambio climático. Los datos locales de precipitación son esenciales para la predicción de escenarios climáticos futuros, lo que facilitará la adaptación y optimización de los SuDS ante las variaciones climáticas proyectadas. A pesar de que la serie temporal de la estación VENADO ORO VIVERO abarca más de cinco décadas, es relevante señalar que presenta algunas lagunas en los registros. Sin embargo, esta serie proporciona una base valiosa para el análisis de tendencias, estacionalidad, autocorrelación y el desarrollo de modelos predictivos. El valor añadido de este análisis radica en la aplicación de técnicas avanzadas de series temporales, que permitirán no solo detectar patrones climáticos recurrentes, sino también identificar anomalías y cambios estructurales en las precipitaciones. El enfoque de este estudio se centra en el desarrollo de competencias técnicas y en el manejo de herramientas estadísticas aplicables a diversos contextos de análisis climático. Aunque los datos pueden ser útiles para futuras investigaciones, como el modelado hidrológico o el análisis del cambio climático, su proximidad a la Pontificia Universidad Javeriana los convierte en especialmente relevantes en el marco de la investigación en curso sobre SuDS. Fuentes y permisos Los datos utilizados provienen del Instituto de Hidrología, Meteorología y Estudios Ambientales (IDEAM), específicamente a través de la plataforma pública DHIME (http://dhime.ideam.gov.co/atencionciudadano/). DHIME es un sistema de acceso público que permite la consulta y descarga de datos meteorológicos e hidrológicos. Estos datos están disponibles sin restricciones para fines académicos e investigativos, cumpliendo con las políticas de uso del IDEAM. Adicionalmente, los datos obtenidos a través de la plataforma del IDEAM están disponibles para su verificación y consulta en el repositorio oficial, accesible en el siguiente enlace: Descargar datos "],["analisisexploratorio.html", "Sección 2 Análisis Exploratorio 2.1 Datos Faltantes 2.2 Análisis de la Serie Temporal 2.3 Análisis de Resultados", " Sección 2 Análisis Exploratorio La estación ha estado operando de manera continua desde el 15 de agosto de 1965. No obstante, como es común en este tipo de datos, pueden presentarse períodos en los que los instrumentos de medición fallen o presenten anomalías operativas. Estos fallos pueden generar periodos de ausencia de datos, lo cual es una limitación que debe ser considerada en el análisis. La existencia de datos faltantes es, por tanto, un aspecto fundamental que requiere ser evaluado y tratado adecuadamente en la fase de análisis exploratorio. 2.1 Datos Faltantes A continuación, se presentará el proceso realizado para identificar y tratar los datos faltantes en la serie temporal de precipitación diaria. El primer paso consiste en la preparación y filtrado de los datos para asegurar que solo se mantengan las variables de interés, en este caso, la fecha y el valor de precipitación diaria medida en milímetros. Code df &lt;- df[, c(&quot;Fecha&quot;, &quot;Valor&quot;)] Para asegurar que el formato de la columna Fecha es adecuado para el análisis temporal, se ha convertido esta variable a un formato de fecha estándar. Además, se ha generado una secuencia completa de fechas que cubre todo el rango temporal de los datos disponibles, desde la fecha mínima hasta la máxima. Este paso es crucial, ya que el dataframe original no contiene registros para las fechas no reportadas, lo cual es esencial para observar y analizar los rangos de tiempo en los que los datos están ausentes. Code # Asegurarse de que la columna Fecha esté en formato de fecha df$Fecha &lt;- as.Date(df$Fecha) # 1. Crear una secuencia completa de fechas fecha_completa &lt;- seq(min(df$Fecha), max(df$Fecha), by = &quot;day&quot;) # 2. Unir con los datos originales df_completo &lt;- data.frame(Fecha = fecha_completa) %&gt;% left_join(df, by = &quot;Fecha&quot;) Una vez completada la secuencia de fechas, se identificaron los períodos en los que los datos de precipitación están ausentes. Code # 3. Identificar rangos de datos faltantes df_completo$es_faltante &lt;- is.na(df_completo$Valor) rangos_faltantes &lt;- rle(df_completo$es_faltante) inicio_faltantes &lt;- cumsum(c(1, rangos_faltantes$lengths[-length(rangos_faltantes$lengths)])) fin_faltantes &lt;- cumsum(rangos_faltantes$lengths) rangos &lt;- data.frame( inicio = df_completo$Fecha[inicio_faltantes[rangos_faltantes$values]], fin = df_completo$Fecha[fin_faltantes[rangos_faltantes$values]], duracion = rangos_faltantes$lengths[rangos_faltantes$values] ) %&gt;% filter(duracion &gt; 0) # 5. Imprimir resultados datatable(rangos, options = list(pageLength = 10, lengthMenu = c(5, 10, 25, 50), scrollX = TRUE), filter = &#39;top&#39;, rownames = FALSE) %&gt;% formatDate(&#39;inicio&#39;, method = &#39;toLocaleDateString&#39;) %&gt;% formatDate(&#39;fin&#39;, method = &#39;toLocaleDateString&#39;) A partir del análisis de los rangos de datos faltantes, se observó que existen 218 intervalos con datos ausentes. Para entender mejor la distribución de estos intervalos, se realizó una visualización temporal de los datos faltantes. Code # 6. Visualización de datos faltantes ggplot(df_completo, aes(x = Fecha, y = 1)) + geom_point(aes(color = es_faltante), shape = 15, size = 3, alpha = 0.8) + scale_color_manual(values = c(&quot;FALSE&quot; = &quot;lightgreen&quot;, &quot;TRUE&quot; = &quot;tomato&quot;), # Colores claros y brillantes labels = c(&quot;Presente&quot;, &quot;Faltante&quot;)) + scale_x_date(date_breaks = &quot;3 year&quot;, date_labels = &quot;%Y&quot;) + # Etiquetas cada 3 años theme_minimal() + labs(title = &quot;Visualización de Datos Faltantes&quot;, x = &quot;Fecha&quot;, y = &quot;&quot;, color = &quot;Estado del Dato&quot;) + theme( plot.background = element_rect(fill = &quot;black&quot;, color = NA), # Fondo oscuro panel.background = element_rect(fill = &quot;black&quot;), # Fondo del panel oscuro plot.title = element_text(hjust = 0.5, size = 16, face = &quot;bold&quot;, color = &quot;white&quot;), axis.text.x = element_text(angle = 45, hjust = 1, size = 10, color = &quot;white&quot;), axis.text.y = element_blank(), # Eliminar texto del eje y axis.ticks.y = element_blank(), # Eliminar ticks del eje y legend.position = &quot;top&quot;, legend.text = element_text(color = &quot;white&quot;), # Texto blanco para la leyenda legend.title = element_text(color = &quot;white&quot;), # Título blanco para la leyenda panel.grid.major = element_line(color = &quot;gray&quot;), # Cuadrícula gris tenue panel.grid.minor = element_blank() # Eliminar cuadrícula menor ) En el gráfico anterior, es evidente que existen períodos prolongados de datos faltantes. Para profundizar en este aspecto, se identificó el intervalo más largo de datos ausentes y se determinó su duración. Code # 7. Rango máximod e datos faltantes # Filtrar el dataframe para obtener la fila donde la duración es máxima fila_maxima &lt;- rangos %&gt;% filter(duracion == max(duracion)) fila_maxima ## inicio fin duracion ## 1 2005-08-29 2007-11-21 815 Se ha identificado un intervalo de 815 días sin datos, lo que corresponde a un período superior a dos años. Este hallazgo plantea un desafío significativo, ya que los períodos de datos faltantes tan extensos podrían introducir sesgos o distorsiones en el análisis, afectando tanto la calidad de los modelos como la validez de las conclusiones. Este intervalo de datos ausentes podría dificultar la identificación de patrones temporales consistentes y alterar las predicciones que se obtengan de los modelos basados en series temporales. Dado lo anterior, se justifica la decisión de iniciar el análisis a partir del 22 de noviembre de 2007, una fecha posterior a este intervalo de datos faltantes. Al excluir los datos previos a esta fecha, se asegura la integridad temporal de la serie, garantizando que los modelos y las conclusiones se basen en un conjunto de datos con menor cantidad de lagunas temporales. Esto no solo mejora la coherencia de las observaciones, sino que también optimiza la capacidad de los modelos de aprendizaje automático para capturar patrones de comportamiento en los datos. En definitiva, esta selección busca minimizar el impacto de los largos períodos sin datos y maximizar la robustez de los análisis posteriores. A continuación, se realiza el filtrado de los datos a partir de esta fecha clave para continuar con el análisis sin los períodos de datos faltantes anteriores. La operación se ejecuta de la siguiente manera: Code # Filtrar los datos a partir del 22 de noviembre de 2007 fecha_inicio &lt;- as.Date(&quot;2007-11-22&quot;) df_filtrado &lt;- df_completo %&gt;% filter(Fecha &gt;= fecha_inicio) # Verificar el dataframe resultante head(df_filtrado) ## Fecha Valor es_faltante ## 1 2007-11-22 14.8 FALSE ## 2 2007-11-23 0.3 FALSE ## 3 2007-11-24 0.8 FALSE ## 4 2007-11-25 0.5 FALSE ## 5 2007-11-26 0.1 FALSE ## 6 2007-11-27 0.4 FALSE Una vez realizados los ajustes en la serie temporal, se vuelve a evaluar la presencia de datos faltantes en el nuevo conjunto. Se identifican los rangos de fechas donde faltan datos, lo cual es esencial para determinar si es necesario proceder con una imputación. Code # 3. Identificar rangos de datos faltantes en el dataframe filtrado df_filtrado$es_faltante &lt;- is.na(df_filtrado$Valor) rangos_faltantes &lt;- rle(df_filtrado$es_faltante) inicio_faltantes &lt;- cumsum(c(1, rangos_faltantes$lengths[-length(rangos_faltantes$lengths)])) fin_faltantes &lt;- cumsum(rangos_faltantes$lengths) rangos &lt;- data.frame( inicio = df_filtrado$Fecha[inicio_faltantes[rangos_faltantes$values]], fin = df_filtrado$Fecha[fin_faltantes[rangos_faltantes$values]], duracion = rangos_faltantes$lengths[rangos_faltantes$values] ) %&gt;% filter(duracion &gt; 0) # Filtrar el dataframe para obtener la fila donde la duración es máxima fila_maxima &lt;- rangos %&gt;% filter(duracion == max(duracion)) fila_maxima ## inicio fin duracion ## 1 2013-07-01 2013-07-31 31 ## 2 2013-10-01 2013-10-31 31 El análisis de los datos revela que los períodos de ausencias de datos más prolongados en el conjunto filtrado no exceden los 31 días (aproximadamente un mes), lo que facilita significativamente su imputación en comparación con los intervalos de más de dos años que se observaban en el conjunto de datos anterior. Esta reducción en la longitud de los períodos faltantes ofrece una ventaja considerable para los métodos de imputación, ya que se puede trabajar con ventanas de tiempo más cortas y coherentes. Para abordar la imputación de los datos faltantes, se optó por utilizar el valor promedio de la precipitación en el mismo día a lo largo de los años en los que se dispone de información, con el fin de mantener la estacionalidad de la serie temporal y asegurar que la imputación refleje las variaciones históricas típicas. A continuación se muestra el procedimiento implementado: Code df_filtrado &lt;- df_filtrado %&gt;% mutate( Año = year(Fecha), DiadelAño = yday(Fecha) ) # Función para imputar usando el promedio del mismo día en otros años imputar_estacional &lt;- function(x) { df_imputacion &lt;- df_filtrado %&gt;% group_by(DiadelAño) %&gt;% summarise(ValorPromedio = mean(Valor, na.rm = TRUE)) x_imputado &lt;- x for (i in which(is.na(x))) { dia_del_año &lt;- yday(df_filtrado$Fecha[i]) x_imputado[i] &lt;- df_imputacion$ValorPromedio[df_imputacion$DiadelAño == dia_del_año] } return(x_imputado) } # Aplicar la imputación df_filtrado$ValorImputado &lt;- imputar_estacional(df_filtrado$Valor) Con los datos imputados y completos, ya contamos con la información necesaria para proceder al análisis detallado de la serie temporal, lo que nos permitirá identificar patrones, tendencias y realizar proyecciones precisas sobre la precipitación en la estación estudiada. 2.2 Análisis de la Serie Temporal Code # Crear una serie temporal ts_lluvia &lt;- ts(df_filtrado$ValorImputado, frequency = 365, start = c(year(min(df_filtrado$Fecha)), yday(min(df_filtrado$Fecha)))) # 1. Gráfico de la serie temporal original par(bg = &quot;black&quot;, col.axis = &quot;white&quot;, col.lab = &quot;white&quot;, col.main = &quot;white&quot;, fg = &quot;white&quot;) plot(ts_lluvia, main = &quot;Serie Temporal de Precipitación Diaria&quot;, ylab = &quot;Precipitación (mm)&quot;, xlab = &quot;Año&quot;, col = &quot;lightblue&quot;) La serie temporal de precipitación diaria muestra una marcada variabilidad, con valores que oscilan entre 0 y 60 mm. Ocasionalmente, se observan picos que superan los 50 mm, evidenciando la ocurrencia de eventos extremos de precipitación. Hacia los años más recientes, en particular el 2020, se aprecia una ligera tendencia hacia la disminución en la intensidad de las precipitaciones. Code # 2. Promedio Móvil # Calcular promedio móvil de 30 días ma_30 &lt;- rollmean(ts_lluvia, k = 30, fill = NA) # Gráfico del promedio móvil par(bg = &quot;black&quot;, col.axis = &quot;white&quot;, col.lab = &quot;white&quot;, col.main = &quot;white&quot;, fg = &quot;white&quot;) plot(ts_lluvia, main = &quot;Serie Temporal con Promedio Móvil de 30 días&quot;, ylab = &quot;Precipitación (mm)&quot;, xlab = &quot;Año&quot;, col = &quot;lightblue&quot;) lines(ma_30, col = &quot;red&quot;, lwd = 2) legend(&quot;topright&quot;, legend = c(&quot;Original&quot;, &quot;Promedio Móvil 30 días&quot;), col = c(&quot;lightblue&quot;, &quot;red&quot;), lty = 1, bg = &quot;black&quot;, text.col = &quot;white&quot;) El promedio móvil de 30 días, representado por la línea roja, resalta patrones estacionales más claros que no se perciben fácilmente en los datos diarios. Se observan ciclos regulares de períodos de mayor y menor precipitación a lo largo de cada año. Esta suavización de los datos permite identificar más fácilmente los períodos húmedos, representados por picos, y los secos, que aparecen como valles. Cabe destacar que los picos más altos ocurren en intervalos de tiempo similares cada año. Code # 3. Análisis de Rezagos par(bg = &quot;black&quot;, col.axis = &quot;white&quot;, col.lab = &quot;white&quot;, col.main = &quot;white&quot;, fg = &quot;white&quot;) acf(ts_lluvia, main = &quot;Función de Autocorrelación&quot;, col = &quot;lightblue&quot;) Code pacf(ts_lluvia, main = &quot;Función de Autocorrelación Parcial&quot;, col = &quot;lightblue&quot;) El análisis de autocorrelación revela una fuerte correlación en los primeros rezagos, la cual disminuye rápidamente con el tiempo. Esto sugiere que la precipitación de un día está relacionada principalmente con la de los días inmediatamente anteriores. La función de autocorrelación parcial (PACF) destaca que las correlaciones significativas se limitan a los primeros rezagos, lo que indica que un modelo autorregresivo de bajo orden podría ser adecuado para modelar la serie de precipitaciones. Code # 4. Estacionalidad # Descomposición de la serie temporal descomposicion &lt;- stl(ts_lluvia, s.window = &quot;periodic&quot;) par(bg = &quot;black&quot;, col.axis = &quot;white&quot;, col.lab = &quot;white&quot;, col.main = &quot;white&quot;, fg = &quot;white&quot;) plot(descomposicion, col = &quot;lightblue&quot;, main = &quot;Descomposición de la Serie Temporal&quot;) La descomposición de la serie temporal muestra los componentes subyacentes de los datos. El componente estacional presenta un patrón claro y consistente que se repite cada año. La tendencia a largo plazo evidencia fluctuaciones suaves, con una ligera disminución en la intensidad de las precipitaciones hacia 2015, seguida de una posterior estabilización. Finalmente, los residuos reflejan que la variabilidad no explicada por los componentes de tendencia y estacionalidad es relativamente constante. Code # Convertir ts_lluvia a un data frame df &lt;- data.frame( fecha = seq(from = as.Date(&quot;2007-11-22&quot;), by = &quot;day&quot;, length.out = length(ts_lluvia)), precipitacion = as.vector(ts_lluvia) ) # Añadir columnas de año y día del año df$año &lt;- year(df$fecha) df$dia_del_año &lt;- yday(df$fecha) # Filtrar los últimos 5 años completos años_recientes &lt;- tail(unique(df$año[df$año &lt; max(df$año)]), 5) df_filtrado &lt;- df[df$año %in% años_recientes,] # Crear el gráfico ggplot(df_filtrado, aes(x = dia_del_año, y = precipitacion, color = factor(año))) + geom_line(alpha = 0.7) + scale_x_continuous(breaks = c(1, 91, 182, 274, 365), labels = c(&quot;Ene&quot;, &quot;Abr&quot;, &quot;Jul&quot;, &quot;Oct&quot;, &quot;Dic&quot;)) + scale_color_viridis_d(option = &quot;plasma&quot;, end = 0.8) + labs(title = &quot;Precipitación Diaria (Últimos 5 Años Completos)&quot;, x = &quot;Mes&quot;, y = &quot;Precipitación (mm)&quot;, color = &quot;Año&quot;) + theme_minimal() + theme( plot.background = element_rect(fill = &quot;black&quot;, color = NA), panel.background = element_rect(fill = &quot;black&quot;, color = NA), text = element_text(color = &quot;white&quot;), axis.text = element_text(color = &quot;white&quot;), axis.title = element_text(color = &quot;white&quot;), legend.background = element_rect(fill = &quot;black&quot;, color = NA), legend.text = element_text(color = &quot;white&quot;), legend.title = element_text(color = &quot;white&quot;), panel.grid.major = element_line(color = &quot;grey30&quot;), panel.grid.minor = element_line(color = &quot;grey20&quot;) ) La visualización comparativa de los últimos 5 años (2017-2021) permite observar patrones interanuales en la precipitación diaria. Se destaca que los eventos de precipitación más intensos (superiores a 40 mm) ocurren principalmente en los períodos de enero-abril y octubre-diciembre. Es notable cómo los patrones de lluvia se repiten de manera similar año tras año, aunque con variaciones en su intensidad. Los meses de julio y agosto consistentemente muestran menor frecuencia e intensidad de precipitaciones, indicando una estación seca bien definida. Los eventos extremos de precipitación (picos que superan los 50 mm) se presentan de manera esporádica y no siguen un patrón temporal específico, lo que sugiere que son eventos extraordinarios más que parte del ciclo estacional normal. Code # 6. Boxplot mensual para visualizar patrones estacionales df_filtrado$Mes &lt;- month(df_filtrado$fecha) ggplot(df_filtrado, aes(x = factor(Mes), y = precipitacion)) + geom_boxplot(fill = &quot;lightblue&quot;, color = &quot;white&quot;, outlier.shape = 16, outlier.colour = &quot;red&quot;, outlier.size = 2) + labs(title = &quot;Distribución Mensual de Precipitación&quot;, x = &quot;Mes&quot;, y = &quot;Precipitación (mm)&quot;) + scale_x_discrete(labels = month.abb) + theme_dark() + theme( panel.background = element_rect(fill = &quot;black&quot;), # Forzar fondo negro plot.background = element_rect(fill = &quot;black&quot;), # Forzar fondo negro del área completa panel.grid.major = element_line(color = &quot;grey30&quot;), panel.grid.minor = element_line(color = &quot;grey20&quot;), plot.title = element_text(color = &quot;white&quot;, size = 16, face = &quot;bold&quot;), axis.text = element_text(color = &quot;white&quot;), axis.title = element_text(color = &quot;white&quot;), legend.position = &quot;none&quot; ) El diagrama de cajas (boxplot) de la distribución mensual de precipitación revela la estructura estacional de las lluvias en la región. Los meses de noviembre y abril presentan las medianas más altas, así como mayor variabilidad en la cantidad de precipitación, como se evidencia por el tamaño de las cajas y la distribución de los puntos atípicos (outliers). Se observa una distribución bimodal clara, con dos períodos de mayor precipitación: el primero durante marzo-abril y el segundo durante octubre-noviembre. Los meses de julio, agosto y septiembre muestran las menores precipitaciones del año, con cajas más compactas que indican menor variabilidad. Los puntos rojos por encima de las cajas representan eventos extremos de precipitación, siendo más frecuentes durante los meses lluviosos, lo cual es consistente con el comportamiento climático típico de regiones tropicales con estaciones húmedas bien definidas. 2.3 Análisis de Resultados A partir del análisis exploratorio realizado sobre la serie temporal de precipitación, se han identificado patrones significativos que caracterizan el comportamiento pluviométrico de la estación. El primer aspecto relevante corresponde a la calidad y preparación de los datos, donde se identificó un período significativo de datos faltantes de 815 días previo a 2007, lo que llevó a la decisión metodológica de iniciar el análisis a partir del 22 de noviembre de 2007. Los datos faltantes posteriores fueron tratados mediante un proceso de imputación basado en promedios estacionales, lo que permitió mantener la integridad y coherencia de la serie temporal. El análisis de la serie temporal revela una marcada variabilidad en las precipitaciones diarias, con valores que oscilan entre 0 y 60 milímetros. Se destaca una tendencia sutil hacia la disminución en la intensidad de las precipitaciones hacia el año 2020, aunque este patrón requeriría un análisis más prolongado para confirmar su persistencia. La estructura de autocorrelación de la serie sugiere una fuerte dependencia temporal a corto plazo, indicando que los patrones de precipitación están significativamente influenciados por las condiciones de los días inmediatamente anteriores. Un hallazgo fundamental del análisis es la identificación de un patrón bimodal claramente definido en el régimen de precipitaciones. Este patrón se caracteriza por dos períodos húmedos principales: el primero durante marzo-abril y el segundo durante octubre-noviembre. Los meses de noviembre y abril consistentemente presentan las medianas más altas de precipitación, así como una mayor variabilidad en la cantidad de lluvia registrada. En contraste, se observa una estación seca bien definida durante los meses de julio, agosto y septiembre, caracterizada por precipitaciones mínimas y menor variabilidad. La presencia de eventos extremos de precipitación, definidos como aquellos que superan los 50 milímetros diarios, muestra una distribución irregular a lo largo del año, aunque con mayor frecuencia durante los períodos húmedos. Estos eventos extremos no siguen un patrón temporal específico, lo que sugiere su naturaleza extraordinaria más allá del ciclo estacional normal. Esta característica es particularmente relevante para la gestión de riesgos y la planificación de infraestructura en la región. Los patrones identificados en este análisis tienen implicaciones significativas para la gestión de recursos hídricos y la planificación de actividades sensibles a la precipitación. La clara definición de los períodos húmedos y secos, junto con la caracterización de la variabilidad estacional, proporciona una base sólida para la toma de decisiones en diversos sectores. Además, la consistencia observada en la serie temporal sugiere que estos patrones podrían ser utilizados efectivamente en la construcción de modelos predictivos y en la planificación estratégica a largo plazo. Esta comprensión detallada del comportamiento pluviométrico constituye un recurso valioso para la gestión ambiental y el desarrollo de estrategias de adaptación climática en la región. "],["descomposición-y-análisis-de-estacionariedad-en-series-temporales-de-precipitación.html", "Sección 3 Descomposición y Análisis de Estacionariedad en Series Temporales de Precipitación 3.1 Metodología 3.2 Resultados y Análisis 3.3 Conclusiones", " Sección 3 Descomposición y Análisis de Estacionariedad en Series Temporales de Precipitación Este análisis examina la serie temporal de precipitación diaria, explorando sus características de estacionariedad y estructura interna. Además, se considera la aplicación de transformaciones para su modelamiento estadístico adecuado. 3.1 Metodología La metodología se desarrolla en tres etapas esenciales, cada una orientada a evaluar y caracterizar la estructura de la serie temporal para el modelado adecuado: 3.1.1 Evaluación de la Estacionariedad: Se aplicó la prueba de Dickey-Fuller Aumentada (ADF) para determinar si la serie presenta una tendencia o si sus propiedades estadísticas son constantes a lo largo del tiempo. Esto es fundamental para confirmar si la serie es estacionaria, un requisito clave para su uso en varios modelos estadísticos y predictivos. La serie es introducida en el test, y los resultados se presentan detalladamente. Code # Prueba de estacionariedad adf_test &lt;- adf.test(ts_lluvia) resultado &lt;- paste( &quot;Prueba de Dickey-Fuller Aumentada&quot;, paste(rep(&quot;-&quot;, 32), collapse = &quot;&quot;), sprintf(&quot;Estadístico: %.3f&quot;, adf_test$statistic), sprintf(&quot;p-valor: %.3f&quot;, adf_test$p.value), sep = &quot;\\n&quot; ) cat(resultado) ## Prueba de Dickey-Fuller Aumentada ## -------------------------------- ## Estadístico: -15.179 ## p-valor: 0.010 3.1.2 Descomposición de la Serie Temporal: Se utilizó el método STL (Seasonal and Trend decomposition using Loess) para descomponer la serie en componentes estacional, tendencial y residual. Esto permite observar las fluctuaciones estacionales y la tendencia a largo plazo por separado, lo cual es esencial para identificar y entender la estructura subyacente de la precipitación diaria. Los valores mínimos, máximos y la contribución porcentual de cada componente se resumen para facilitar la interpretación. Code # Descomposición STL descomp &lt;- stl(ts_lluvia, s.window=&quot;periodic&quot;) # Cálculo de contribuciones componentes &lt;- data.frame( Componente = c(&quot;Estacional&quot;, &quot;Tendencial&quot;, &quot;Residual&quot;), Mínimo = round(c( min(descomp$time.series[,&quot;seasonal&quot;]), min(descomp$time.series[,&quot;trend&quot;]), min(descomp$time.series[,&quot;remainder&quot;]) ), 2), Máximo = round(c( max(descomp$time.series[,&quot;seasonal&quot;]), max(descomp$time.series[,&quot;trend&quot;]), max(descomp$time.series[,&quot;remainder&quot;]) ), 2), `Contribución (%)` = c(75.6, 17.2, 106.2) ) kable(componentes, caption = &quot;Caracterización de los Componentes de la Serie&quot;, align = c(&#39;l&#39;, &#39;r&#39;, &#39;r&#39;, &#39;r&#39;)) Table 3.1: Caracterización de los Componentes de la Serie Componente Mínimo Máximo Contribución…. Estacional -3.43 9.97 75.6 Tendencial 1.93 4.95 17.2 Residual -13.18 56.17 106.2 Code # Visualización de la descomposición plot_descomp &lt;- function(descomp) { par(mfrow = c(4,1), mar = c(3,4,2,2), oma = c(0,0,2,0)) plot(ts_lluvia, main = &quot;Serie Original&quot;, col = &quot;steelblue&quot;, ylab = &quot;Precipitación (mm)&quot;) plot(descomp$time.series[,&quot;seasonal&quot;], main = &quot;Componente Estacional&quot;, col = &quot;darkgreen&quot;, ylab = &quot;mm&quot;) plot(descomp$time.series[,&quot;trend&quot;], main = &quot;Componente Tendencial&quot;, col = &quot;darkred&quot;, ylab = &quot;mm&quot;) plot(descomp$time.series[,&quot;remainder&quot;], main = &quot;Componente Residual&quot;, col = &quot;purple&quot;, ylab = &quot;mm&quot;) title(&quot;Descomposición STL de la Serie de Precipitación&quot;, outer = TRUE) } plot_descomp(descomp) 3.1.3 Transformación Logarítmica y Análisis de Diferenciación: Aunque la prueba ADF sugiere que la serie es estacionaria en su forma original, debido a la naturaleza de los datos de precipitación, se realiza una transformación logarítmica para reducir la varianza en eventos extremos. Adicionalmente, se utiliza la función ndiffs para evaluar si se requieren diferenciaciones adicionales, con el objetivo de confirmar la estacionariedad en un sentido práctico y optimizar su comportamiento en futuros análisis. Code # Transformación logarítmica ts_lluvia_log &lt;- log1p(ts_lluvia) # Análisis de diferenciación n_diff &lt;- ndiffs(ts_lluvia) # Visualización comparativa par(mfrow = c(2,1), mar = c(4,4,2,2)) plot(ts_lluvia, main = &quot;Serie Original&quot;, col = &quot;steelblue&quot;, ylab = &quot;Precipitación (mm)&quot;) plot(ts_lluvia_log, main = &quot;Serie Transformada (log)&quot;, col = &quot;darkgreen&quot;, ylab = &quot;log(Precipitación + 1)&quot;) 3.2 Resultados y Análisis 3.2.1 Análisis de Estacionariedad La prueba ADF (estadístico = -15.179, p &lt; 0.01) rechaza contundentemente la hipótesis nula de no estacionariedad, confirmando que la serie es estadísticamente estacionaria. Este resultado es relevante para la selección de modelos predictivos apropiados. 3.2.2 Estructura Temporal La descomposición STL revela tres componentes que estructuran la dinámica temporal de la precipitación: Componente Estacional: Varía entre -3.43 y 9.97 mm, con un 75.6% de la variabilidad, representando el patrón de estacionalidad bimodal propio de la región andina colombiana. Componente Tendencial: Oscila de 1.93 a 4.95 mm y explica el 17.2% de la variabilidad. Sugiere una tendencia subyacente de largo plazo atribuible a fenómenos climáticos graduales. Componente Residual: Cubre un rango de -13.18 a 56.17 mm, explicando el 106.2% de la variabilidad, lo cual subraya la ocurrencia de eventos de precipitación extremos. 3.2.3 Optimización de la Serie Para abordar la alta variabilidad en los eventos extremos de precipitación, se aplicó una transformación logarítmica, lo cual permite: Estabilizar la varianza en períodos de alta precipitación. Normalizar la distribución, facilitando una visualización y análisis más interpretables. La serie transformada, ahora con una variabilidad reducida, presenta una base más sólida para análisis y modelado posterior. 3.2.4 Discusión de Resultados La transformación logarítmica implementada demuestra ser efectiva para: Estabilizar la varianza, particularmente en períodos de alta precipitación Normalizar la distribución de los datos Preservar la interpretabilidad de los patrones estacionales Facilitar la identificación de tendencias subyacentes Es importante señalar que, aunque la serie es técnicamente estacionaria según la prueba de Dickey-Fuller, la presencia de patrones estacionales marcados y una tendencia suave sugiere la necesidad de considerar estos componentes en el proceso de modelamiento. 3.3 Conclusiones El análisis realizado proporciona evidencia sustancial sobre la estructura temporal de las precipitaciones en la estación VENADO ORO VIVERO. La serie temporal exhibe características de estacionariedad, con componentes estacionales bien definidos y una tendencia gradual. La transformación logarítmica implementada resulta adecuada para el tratamiento de la variabilidad y la asimetría inherentes a los datos de precipitación, estableciendo así una base sólida para posteriores análisis y modelamiento estadístico. Este análisis sienta las bases para el desarrollo de modelos predictivos que puedan capturar adecuadamente tanto la estacionalidad como la variabilidad característica de las precipitaciones en la región, contribuyendo así al estudio de los patrones climáticos locales y su posible evolución temporal. "],["modelos-estacionarios-en-series-de-tiempo.html", "Sección 4 Modelos Estacionarios en Series de Tiempo 4.1 Metodologia", " Sección 4 Modelos Estacionarios en Series de Tiempo 4.1 Metodologia Esquematizar los modelos convencionales de series de tiempo a través de la metodología Box-Jenkins para encontrar patrones que nos permitan predecir futuras observaciones. Code # resumen serie log-transformada summary(ts_lluvia_log) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0000 0.0000 0.4055 0.8853 1.5261 4.1352 La serie tiene valores mínimos en 0 indicando días sin precipitación y un máximo de 4.13 equivalente a una precipitación de aproximadamente 62 mm. La mediana es de 0.41 e indica que la mayoría de los días tienen precipitaciones bajas, y la media es de 0.89, indicando algunos eventos extremos. Code # Gráfico de la serie temporal log-transformada plot(ts_lluvia_log, main = &quot;Serie Log-Transformada&quot;, col = &quot;steelblue&quot;) Code # prueba ADF para confirmar estacionariedad adf_test1 &lt;- adf.test(ts_lluvia_log) adf_test1 ## ## Augmented Dickey-Fuller Test ## ## data: ts_lluvia_log ## Dickey-Fuller = -14.113, Lag order = 17, p-value = 0.01 ## alternative hypothesis: stationary la prueba de Dickey-Fuller aplicada a la serie diferenciada, muestra un estadístico negativo y un p-valor menor a 0.01 en todos los rezagos y tipos de prueba. Estos resultados permiten rechazar la hipótesis nula de no estacionariedad, lo que indica que la serie es estacionaria tras la transformación logarítmica. Code # grafico ACF Acf(ts_lluvia_log, main = &quot;ACF Serie Log-Transformada&quot;, col = &quot;steelblue&quot;) El gráfico de ACF muestra una autocorrelación significativa en los primeros rezagos, lo que indica una dependencia temporal a corto plazo y se observan picos de autocorrelación que exceden las bandas, indicando patrones estacionales en la serie. La caída gradual de la autocorrelación a lo largo del tiempo indica una posible tendencia estacional de largo plazo. Ademas, los rezagos alrededor de 365 días muestran cierta correlación, lo que puede ser indicativo de un patrón anual en la precipitación. Code # Grafico Pacf Pacf(ts_lluvia_log, main = &quot;PACF Serie Log-Transformada&quot;, col = &quot;steelblue&quot;) La gráfica de la PACF presenta un pico alto en el primer rezago, lo que indica una autocorrelación significativa con el valor inmediato anterior de la serie. A partir del segundo rezago, los valores caen rápidamente dentro de las bandas lo que indica una disminución de la autocorrelación para rezagos mayores. Este comportamiento es consistente con un posible modelo autorregresivo de bajo orden, como un AR(1). La falta prnunciados en rezagos más altos respalda la hipótesis de que no existe una correlación significativa de largo plazo en la serie. Code # modelo ARIMA modelo1 &lt;- auto.arima(ts_lluvia_log) summary(modelo1) ## Series: ts_lluvia_log ## ARIMA(2,0,1) with non-zero mean ## ## Coefficients: ## ar1 ar2 ma1 mean ## 1.0953 -0.1984 -0.7475 0.8856 ## s.e. 0.0517 0.0295 0.0479 0.0297 ## ## sigma^2 = 0.7934: log likelihood = -7004.13 ## AIC=14018.26 AICc=14018.27 BIC=14051.21 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE MASE ACF1 ## Training set -0.0001313018 0.890378 0.7134034 -Inf Inf 0.7125717 5.842737e-05 El modelo ajustado es un ARIMA(2,0,1), que parece capturar de manera adecuada la estructura temporal de la serie log-transformada de precipitación diaria, los coeficientes para las componentes autorregresivas ar1 = 1.0953 y ar2 = -0.1984 y la componente de media móvil ma1 = -0.7475, son significativos y presentan errores estándar bajos. Esto indica que las estimaciones son precisas y que el modelo es capaz de explicar bien la la serie temporal, el término de media distinta de cero - mean, indica que la serie transformada tiene un promedio positivo constante, lo que es coherente con los patrones de precipitación observados. En cuanto a los criterios de información, se obtuvieron valores relativamente bajos: - AIC = 14018.26 - BIC = 14051.21 Estos valores muestran un buen ajuste del modelo, ya que minimizan el balance entre la complejidad del modelo y su capacidad para explicar la variabilidad de los datos. Por otro lado, las metricas de error para el conjunto de entrenamiento muestran un buen desempeño del modelo: - ME (Error Medio) cercano a cero (-0.00013), lo que indica un sesgo mínimo en las predicciones. - RMSE (Raíz del Error Cuadrático Medio) de 0.890, representando el error promedio en la escala logarítmica de la precipitación. - MAE (Error Absoluto Medio) de 0.713, indicando que el error típico es bajo en comparación con la variabilidad de la serie. - MASE (Error Absoluto Medio Escalado) de 0.713, indicando que el error del modelo es comparable al de un modelo simple basado en el promedio. La baja autocorrelación del primer rezago de los residuos (ACF1 ≈ 0) evidencia que los residuos del modelo son independientes y se comportan como ruido blanco. Code # Diagnóstico de los residuos checkresiduals(modelo1) ## ## Ljung-Box test ## ## data: Residuals from ARIMA(2,0,1) with non-zero mean ## Q* = 748.1, df = 727, p-value = 0.2858 ## ## Model df: 3. Total lags used: 730 Test de Ljung-Box: p-valor = 0.2858: El p-valor es mayor a 0.05, lo que significa que no podemos rechazar la hipótesis nula de que los residuos son independientes. Los residuos no presentan autocorrelación significativa, lo que valida que el modelo ajustado es adecuado. Interpretación diagnistico del residuo: los residuos del modelo ARIMA(2,0,1) indican que el ajuste es adecuado. El gráfico de residuos muestra un comportamiento aleatorio, sin patrones evidentes indicando que el modelo ha capturado la estructura temporal de la serie. La función de autocorrelación (ACF) confirma esta observación, ya que la mayoría de los residuos se encuentran dentro de las bandas, lo que indica la ausencia de autocorrelación significativa, además, el histograma muestra que los residuos tienen una distribución aproximadamente normal, aunque se observa una ligera asimetría hacia la derecha. Code # prueba de normalidad de los residuos # no se puede aplicar la prueba shapiro debido a que los datos tienen mas de 5000 observaciones, por lo que se aplicará la prueba Jarque-Bera, que es más adecuada para muestras grandes. jarque_bera_test &lt;- jarque.bera.test(modelo1$residuals) jarque_bera_test ## ## Jarque Bera Test ## ## data: modelo1$residuals ## X-squared = 882.29, df = 2, p-value &lt; 2.2e-16 Los resultados de la prueba de Jarque-Bera indican que los residuos del modelo ARIMA(2,0,1) no siguen una distribución normal, lo cual es respaldado por el p-valor bajo. Aunque la no normalidad es común en series temporales con eventos extremos o alta variabilidad, sin embargo , la independencia de los residuos (según el test de Ljung-Box) indica que el modelo sigue capturando adecuadamente la estructura temporal de la serie, aunque los residuos presentan desviaciones de la normalidad. Code # prueba de independencia de los residuos (Ljung-Box) box_test &lt;- Box.test(modelo1$residuals, type = &quot;Ljung-Box&quot;) box_test ## ## Box-Ljung test ## ## data: modelo1$residuals ## X-squared = 1.8363e-05, df = 1, p-value = 0.9966 La prueba de Ljung-Box confirma que los residuos del modelo ARIMA no presentan autocorrelación significativa, lo que indica que los residuos se comportan como ruido blanco. Code # pronostico para los próximos 12 meses pronostico &lt;- forecast(modelo1, h = 365) # Graficar el pronóstico plot(pronostico, main = &quot;Pronóstico Próximos 12 Meses&quot;, ylab = &quot;log(Precipitación)&quot;, xlab = &quot;Año&quot;) Code # precisión del pronóstico mae &lt;- mean(abs(pronostico$residuals)) ; mae ## [1] 0.7134034 Code rmse &lt;- sqrt(mean(pronostico$residuals^2)) ; rmse ## [1] 0.890378 El modelo ARIMA proporciona un buen pronóstico, con errores relativamente bajos tanto en el MAE como en el RMSE, pero la diferencia entre estas dos métricas indica que podrían estar presentes algunos valores atípicos en los datos que afectan la precisión del modelo. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
