[["index.html", "Análisis de Series Temporales de Lluvia: Estación VENADO ORO VIVERO [21205580] Sección 1 Importancia del Análisis de la Precipitación", " Análisis de Series Temporales de Lluvia: Estación VENADO ORO VIVERO [21205580] Dónoban Rojas Sección 1 Importancia del Análisis de la Precipitación Se propone el análisis de los datos de precipitación diaria registrados en la estación climatológica “VENADO ORO VIVERO”, ubicada en Bogotá, con coordenadas 4.60° de latitud y -74.06° de longitud, y una altitud de 2,725 metros sobre el nivel del mar. Esta estación, parte de la red del Instituto de Hidrología, Meteorología y Estudios Ambientales (IDEAM), cuenta con datos históricos desde el 1 de agosto de 1965 hasta el 10 de agosto de 2022. La variable seleccionada es la precipitación diaria (PTPM_CON), medida en milímetros (mm). Justificación del uso de datos de precipitación El análisis de las series temporales de precipitación es fundamental para comprender las características climáticas locales y su evolución a lo largo del tiempo. Este tipo de estudio permite identificar patrones estacionales, tendencias a largo plazo y fenómenos extremos, aspectos cruciales para pronosticar eventos climáticos relevantes. La estación VENADO ORO VIVERO ha sido seleccionada por su accesibilidad de datos y su cercanía a la Pontificia Universidad Javeriana sede Bogotá, donde actualmente se lleva a cabo una investigación aplicada sobre Sistemas Urbanos de Drenaje Sostenible (SuDS) en el contexto del cambio climático. Los datos locales de precipitación son esenciales para la predicción de escenarios climáticos futuros, lo que facilitará la adaptación y optimización de los SuDS ante las variaciones climáticas proyectadas. A pesar de que la serie temporal de la estación VENADO ORO VIVERO abarca más de cinco décadas, es relevante señalar que presenta algunas lagunas en los registros. Sin embargo, esta serie proporciona una base valiosa para el análisis de tendencias, estacionalidad, autocorrelación y el desarrollo de modelos predictivos. El valor añadido de este análisis radica en la aplicación de técnicas avanzadas de series temporales, que permitirán no solo detectar patrones climáticos recurrentes, sino también identificar anomalías y cambios estructurales en las precipitaciones. El enfoque de este estudio se centra en el desarrollo de competencias técnicas y en el manejo de herramientas estadísticas aplicables a diversos contextos de análisis climático. Aunque los datos pueden ser útiles para futuras investigaciones, como el modelado hidrológico o el análisis del cambio climático, su proximidad a la Pontificia Universidad Javeriana los convierte en especialmente relevantes en el marco de la investigación en curso sobre SuDS. Fuentes y permisos Los datos utilizados provienen del Instituto de Hidrología, Meteorología y Estudios Ambientales (IDEAM), específicamente a través de la plataforma pública DHIME (http://dhime.ideam.gov.co/atencionciudadano/). DHIME es un sistema de acceso público que permite la consulta y descarga de datos meteorológicos e hidrológicos. Estos datos están disponibles sin restricciones para fines académicos e investigativos, cumpliendo con las políticas de uso del IDEAM. Adicionalmente, los datos obtenidos a través de la plataforma del IDEAM están disponibles para su verificación y consulta en el repositorio oficial, accesible en el siguiente enlace: Descargar datos "],["analisisexploratorio.html", "Sección 2 Análisis Exploratorio 2.1 Datos Faltantes 2.2 Análisis de la Serie Temporal 2.3 Análisis de Resultados", " Sección 2 Análisis Exploratorio La estación ha estado operando de manera continua desde el 15 de agosto de 1965. No obstante, como es común en este tipo de datos, pueden presentarse períodos en los que los instrumentos de medición fallen o presenten anomalías operativas. Estos fallos pueden generar periodos de ausencia de datos, lo cual es una limitación que debe ser considerada en el análisis. La existencia de datos faltantes es, por tanto, un aspecto fundamental que requiere ser evaluado y tratado adecuadamente en la fase de análisis exploratorio. 2.1 Datos Faltantes A continuación, se presentará el proceso realizado para identificar y tratar los datos faltantes en la serie temporal de precipitación diaria. El primer paso consiste en la preparación y filtrado de los datos para asegurar que solo se mantengan las variables de interés, en este caso, la fecha y el valor de precipitación diaria medida en milímetros. Code df &lt;- df[, c(&quot;Fecha&quot;, &quot;Valor&quot;)] Para asegurar que el formato de la columna Fecha es adecuado para el análisis temporal, se ha convertido esta variable a un formato de fecha estándar. Además, se ha generado una secuencia completa de fechas que cubre todo el rango temporal de los datos disponibles, desde la fecha mínima hasta la máxima. Este paso es crucial, ya que el dataframe original no contiene registros para las fechas no reportadas, lo cual es esencial para observar y analizar los rangos de tiempo en los que los datos están ausentes. Code # Asegurarse de que la columna Fecha esté en formato de fecha df$Fecha &lt;- as.Date(df$Fecha) # 1. Crear una secuencia completa de fechas fecha_completa &lt;- seq(min(df$Fecha), max(df$Fecha), by = &quot;day&quot;) # 2. Unir con los datos originales df_completo &lt;- data.frame(Fecha = fecha_completa) %&gt;% left_join(df, by = &quot;Fecha&quot;) Una vez completada la secuencia de fechas, se identificaron los períodos en los que los datos de precipitación están ausentes. Code # 3. Identificar rangos de datos faltantes df_completo$es_faltante &lt;- is.na(df_completo$Valor) rangos_faltantes &lt;- rle(df_completo$es_faltante) inicio_faltantes &lt;- cumsum(c(1, rangos_faltantes$lengths[-length(rangos_faltantes$lengths)])) fin_faltantes &lt;- cumsum(rangos_faltantes$lengths) rangos &lt;- data.frame( inicio = df_completo$Fecha[inicio_faltantes[rangos_faltantes$values]], fin = df_completo$Fecha[fin_faltantes[rangos_faltantes$values]], duracion = rangos_faltantes$lengths[rangos_faltantes$values] ) %&gt;% filter(duracion &gt; 0) # 5. Imprimir resultados datatable(rangos, options = list(pageLength = 10, lengthMenu = c(5, 10, 25, 50), scrollX = TRUE), filter = &#39;top&#39;, rownames = FALSE) %&gt;% formatDate(&#39;inicio&#39;, method = &#39;toLocaleDateString&#39;) %&gt;% formatDate(&#39;fin&#39;, method = &#39;toLocaleDateString&#39;) A partir del análisis de los rangos de datos faltantes, se observó que existen 218 intervalos con datos ausentes. Para entender mejor la distribución de estos intervalos, se realizó una visualización temporal de los datos faltantes. Code # 6. Visualización de datos faltantes ggplot(df_completo, aes(x = Fecha, y = 1)) + geom_point(aes(color = es_faltante), shape = 15, size = 3, alpha = 0.8) + scale_color_manual(values = c(&quot;FALSE&quot; = &quot;lightgreen&quot;, &quot;TRUE&quot; = &quot;tomato&quot;), # Colores claros y brillantes labels = c(&quot;Presente&quot;, &quot;Faltante&quot;)) + scale_x_date(date_breaks = &quot;3 year&quot;, date_labels = &quot;%Y&quot;) + # Etiquetas cada 3 años theme_minimal() + labs(title = &quot;Visualización de Datos Faltantes&quot;, x = &quot;Fecha&quot;, y = &quot;&quot;, color = &quot;Estado del Dato&quot;) + theme( plot.background = element_rect(fill = &quot;black&quot;, color = NA), # Fondo oscuro panel.background = element_rect(fill = &quot;black&quot;), # Fondo del panel oscuro plot.title = element_text(hjust = 0.5, size = 16, face = &quot;bold&quot;, color = &quot;white&quot;), axis.text.x = element_text(angle = 45, hjust = 1, size = 10, color = &quot;white&quot;), axis.text.y = element_blank(), # Eliminar texto del eje y axis.ticks.y = element_blank(), # Eliminar ticks del eje y legend.position = &quot;top&quot;, legend.text = element_text(color = &quot;white&quot;), # Texto blanco para la leyenda legend.title = element_text(color = &quot;white&quot;), # Título blanco para la leyenda panel.grid.major = element_line(color = &quot;gray&quot;), # Cuadrícula gris tenue panel.grid.minor = element_blank() # Eliminar cuadrícula menor ) En el gráfico anterior, es evidente que existen períodos prolongados de datos faltantes. Para profundizar en este aspecto, se identificó el intervalo más largo de datos ausentes y se determinó su duración. Code # 7. Rango máximod e datos faltantes # Filtrar el dataframe para obtener la fila donde la duración es máxima fila_maxima &lt;- rangos %&gt;% filter(duracion == max(duracion)) fila_maxima ## inicio fin duracion ## 1 2005-08-29 2007-11-21 815 Se ha identificado un intervalo de 815 días sin datos, lo que corresponde a un período superior a dos años. Este hallazgo plantea un desafío significativo, ya que los períodos de datos faltantes tan extensos podrían introducir sesgos o distorsiones en el análisis, afectando tanto la calidad de los modelos como la validez de las conclusiones. Este intervalo de datos ausentes podría dificultar la identificación de patrones temporales consistentes y alterar las predicciones que se obtengan de los modelos basados en series temporales. Dado lo anterior, se justifica la decisión de iniciar el análisis a partir del 22 de noviembre de 2007, una fecha posterior a este intervalo de datos faltantes. Al excluir los datos previos a esta fecha, se asegura la integridad temporal de la serie, garantizando que los modelos y las conclusiones se basen en un conjunto de datos con menor cantidad de lagunas temporales. Esto no solo mejora la coherencia de las observaciones, sino que también optimiza la capacidad de los modelos de aprendizaje automático para capturar patrones de comportamiento en los datos. En definitiva, esta selección busca minimizar el impacto de los largos períodos sin datos y maximizar la robustez de los análisis posteriores. A continuación, se realiza el filtrado de los datos a partir de esta fecha clave para continuar con el análisis sin los períodos de datos faltantes anteriores. La operación se ejecuta de la siguiente manera: Code # Filtrar los datos a partir del 22 de noviembre de 2007 fecha_inicio &lt;- as.Date(&quot;2007-11-22&quot;) df_filtrado &lt;- df_completo %&gt;% filter(Fecha &gt;= fecha_inicio) # Verificar el dataframe resultante head(df_filtrado) ## Fecha Valor es_faltante ## 1 2007-11-22 14.8 FALSE ## 2 2007-11-23 0.3 FALSE ## 3 2007-11-24 0.8 FALSE ## 4 2007-11-25 0.5 FALSE ## 5 2007-11-26 0.1 FALSE ## 6 2007-11-27 0.4 FALSE Una vez realizados los ajustes en la serie temporal, se vuelve a evaluar la presencia de datos faltantes en el nuevo conjunto. Se identifican los rangos de fechas donde faltan datos, lo cual es esencial para determinar si es necesario proceder con una imputación. Code # 3. Identificar rangos de datos faltantes en el dataframe filtrado df_filtrado$es_faltante &lt;- is.na(df_filtrado$Valor) rangos_faltantes &lt;- rle(df_filtrado$es_faltante) inicio_faltantes &lt;- cumsum(c(1, rangos_faltantes$lengths[-length(rangos_faltantes$lengths)])) fin_faltantes &lt;- cumsum(rangos_faltantes$lengths) rangos &lt;- data.frame( inicio = df_filtrado$Fecha[inicio_faltantes[rangos_faltantes$values]], fin = df_filtrado$Fecha[fin_faltantes[rangos_faltantes$values]], duracion = rangos_faltantes$lengths[rangos_faltantes$values] ) %&gt;% filter(duracion &gt; 0) # Filtrar el dataframe para obtener la fila donde la duración es máxima fila_maxima &lt;- rangos %&gt;% filter(duracion == max(duracion)) fila_maxima ## inicio fin duracion ## 1 2013-07-01 2013-07-31 31 ## 2 2013-10-01 2013-10-31 31 El análisis de los datos revela que los períodos de ausencias de datos más prolongados en el conjunto filtrado no exceden los 31 días (aproximadamente un mes), lo que facilita significativamente su imputación en comparación con los intervalos de más de dos años que se observaban en el conjunto de datos anterior. Esta reducción en la longitud de los períodos faltantes ofrece una ventaja considerable para los métodos de imputación, ya que se puede trabajar con ventanas de tiempo más cortas y coherentes. Para abordar la imputación de los datos faltantes, se optó por utilizar el valor promedio de la precipitación en el mismo día a lo largo de los años en los que se dispone de información, con el fin de mantener la estacionalidad de la serie temporal y asegurar que la imputación refleje las variaciones históricas típicas. A continuación se muestra el procedimiento implementado: Code df_filtrado &lt;- df_filtrado %&gt;% mutate( Año = year(Fecha), DiadelAño = yday(Fecha) ) # Función para imputar usando el promedio del mismo día en otros años imputar_estacional &lt;- function(x) { df_imputacion &lt;- df_filtrado %&gt;% group_by(DiadelAño) %&gt;% summarise(ValorPromedio = mean(Valor, na.rm = TRUE)) x_imputado &lt;- x for (i in which(is.na(x))) { dia_del_año &lt;- yday(df_filtrado$Fecha[i]) x_imputado[i] &lt;- df_imputacion$ValorPromedio[df_imputacion$DiadelAño == dia_del_año] } return(x_imputado) } # Aplicar la imputación df_filtrado$ValorImputado &lt;- imputar_estacional(df_filtrado$Valor) Con los datos imputados y completos, ya contamos con la información necesaria para proceder al análisis detallado de la serie temporal, lo que nos permitirá identificar patrones, tendencias y realizar proyecciones precisas sobre la precipitación en la estación estudiada. 2.2 Análisis de la Serie Temporal Code # Crear una serie temporal ts_lluvia &lt;- ts(df_filtrado$ValorImputado, frequency = 365, start = c(year(min(df_filtrado$Fecha)), yday(min(df_filtrado$Fecha)))) # 1. Gráfico de la serie temporal original par(bg = &quot;black&quot;, col.axis = &quot;white&quot;, col.lab = &quot;white&quot;, col.main = &quot;white&quot;, fg = &quot;white&quot;) plot(ts_lluvia, main = &quot;Serie Temporal de Precipitación Diaria&quot;, ylab = &quot;Precipitación (mm)&quot;, xlab = &quot;Año&quot;, col = &quot;lightblue&quot;) La serie temporal de precipitación diaria muestra una marcada variabilidad, con valores que oscilan entre 0 y 60 mm. Ocasionalmente, se observan picos que superan los 50 mm, evidenciando la ocurrencia de eventos extremos de precipitación. Hacia los años más recientes, en particular el 2020, se aprecia una ligera tendencia hacia la disminución en la intensidad de las precipitaciones. Code # 2. Promedio Móvil # Calcular promedio móvil de 30 días ma_30 &lt;- rollmean(ts_lluvia, k = 30, fill = NA) # Gráfico del promedio móvil par(bg = &quot;black&quot;, col.axis = &quot;white&quot;, col.lab = &quot;white&quot;, col.main = &quot;white&quot;, fg = &quot;white&quot;) plot(ts_lluvia, main = &quot;Serie Temporal con Promedio Móvil de 30 días&quot;, ylab = &quot;Precipitación (mm)&quot;, xlab = &quot;Año&quot;, col = &quot;lightblue&quot;) lines(ma_30, col = &quot;red&quot;, lwd = 2) legend(&quot;topright&quot;, legend = c(&quot;Original&quot;, &quot;Promedio Móvil 30 días&quot;), col = c(&quot;lightblue&quot;, &quot;red&quot;), lty = 1, bg = &quot;black&quot;, text.col = &quot;white&quot;) El promedio móvil de 30 días, representado por la línea roja, resalta patrones estacionales más claros que no se perciben fácilmente en los datos diarios. Se observan ciclos regulares de períodos de mayor y menor precipitación a lo largo de cada año. Esta suavización de los datos permite identificar más fácilmente los períodos húmedos, representados por picos, y los secos, que aparecen como valles. Cabe destacar que los picos más altos ocurren en intervalos de tiempo similares cada año. Code # 3. Análisis de Rezagos par(bg = &quot;black&quot;, col.axis = &quot;white&quot;, col.lab = &quot;white&quot;, col.main = &quot;white&quot;, fg = &quot;white&quot;) acf(ts_lluvia, main = &quot;Función de Autocorrelación&quot;, col = &quot;lightblue&quot;) Code pacf(ts_lluvia, main = &quot;Función de Autocorrelación Parcial&quot;, col = &quot;lightblue&quot;) El análisis de autocorrelación revela una fuerte correlación en los primeros rezagos, la cual disminuye rápidamente con el tiempo. Esto sugiere que la precipitación de un día está relacionada principalmente con la de los días inmediatamente anteriores. La función de autocorrelación parcial (PACF) destaca que las correlaciones significativas se limitan a los primeros rezagos, lo que indica que un modelo autorregresivo de bajo orden podría ser adecuado para modelar la serie de precipitaciones. Code # 4. Estacionalidad # Descomposición de la serie temporal descomposicion &lt;- stl(ts_lluvia, s.window = &quot;periodic&quot;) par(bg = &quot;black&quot;, col.axis = &quot;white&quot;, col.lab = &quot;white&quot;, col.main = &quot;white&quot;, fg = &quot;white&quot;) plot(descomposicion, col = &quot;lightblue&quot;, main = &quot;Descomposición de la Serie Temporal&quot;) La descomposición de la serie temporal muestra los componentes subyacentes de los datos. El componente estacional presenta un patrón claro y consistente que se repite cada año. La tendencia a largo plazo evidencia fluctuaciones suaves, con una ligera disminución en la intensidad de las precipitaciones hacia 2015, seguida de una posterior estabilización. Finalmente, los residuos reflejan que la variabilidad no explicada por los componentes de tendencia y estacionalidad es relativamente constante. Code # Convertir ts_lluvia a un data frame df &lt;- data.frame( fecha = seq(from = as.Date(&quot;2007-11-22&quot;), by = &quot;day&quot;, length.out = length(ts_lluvia)), precipitacion = as.vector(ts_lluvia) ) # Añadir columnas de año y día del año df$año &lt;- year(df$fecha) df$dia_del_año &lt;- yday(df$fecha) # Filtrar los últimos 5 años completos años_recientes &lt;- tail(unique(df$año[df$año &lt; max(df$año)]), 5) df_filtrado &lt;- df[df$año %in% años_recientes,] # Crear el gráfico ggplot(df_filtrado, aes(x = dia_del_año, y = precipitacion, color = factor(año))) + geom_line(alpha = 0.7) + scale_x_continuous(breaks = c(1, 91, 182, 274, 365), labels = c(&quot;Ene&quot;, &quot;Abr&quot;, &quot;Jul&quot;, &quot;Oct&quot;, &quot;Dic&quot;)) + scale_color_viridis_d(option = &quot;plasma&quot;, end = 0.8) + labs(title = &quot;Precipitación Diaria (Últimos 5 Años Completos)&quot;, x = &quot;Mes&quot;, y = &quot;Precipitación (mm)&quot;, color = &quot;Año&quot;) + theme_minimal() + theme( plot.background = element_rect(fill = &quot;black&quot;, color = NA), panel.background = element_rect(fill = &quot;black&quot;, color = NA), text = element_text(color = &quot;white&quot;), axis.text = element_text(color = &quot;white&quot;), axis.title = element_text(color = &quot;white&quot;), legend.background = element_rect(fill = &quot;black&quot;, color = NA), legend.text = element_text(color = &quot;white&quot;), legend.title = element_text(color = &quot;white&quot;), panel.grid.major = element_line(color = &quot;grey30&quot;), panel.grid.minor = element_line(color = &quot;grey20&quot;) ) La visualización comparativa de los últimos 5 años (2017-2021) permite observar patrones interanuales en la precipitación diaria. Se destaca que los eventos de precipitación más intensos (superiores a 40 mm) ocurren principalmente en los períodos de enero-abril y octubre-diciembre. Es notable cómo los patrones de lluvia se repiten de manera similar año tras año, aunque con variaciones en su intensidad. Los meses de julio y agosto consistentemente muestran menor frecuencia e intensidad de precipitaciones, indicando una estación seca bien definida. Los eventos extremos de precipitación (picos que superan los 50 mm) se presentan de manera esporádica y no siguen un patrón temporal específico, lo que sugiere que son eventos extraordinarios más que parte del ciclo estacional normal. Code # 6. Boxplot mensual para visualizar patrones estacionales df_filtrado$Mes &lt;- month(df_filtrado$fecha) ggplot(df_filtrado, aes(x = factor(Mes), y = precipitacion)) + geom_boxplot(fill = &quot;lightblue&quot;, color = &quot;white&quot;, outlier.shape = 16, outlier.colour = &quot;red&quot;, outlier.size = 2) + labs(title = &quot;Distribución Mensual de Precipitación&quot;, x = &quot;Mes&quot;, y = &quot;Precipitación (mm)&quot;) + scale_x_discrete(labels = month.abb) + theme_dark() + theme( panel.background = element_rect(fill = &quot;black&quot;), # Forzar fondo negro plot.background = element_rect(fill = &quot;black&quot;), # Forzar fondo negro del área completa panel.grid.major = element_line(color = &quot;grey30&quot;), panel.grid.minor = element_line(color = &quot;grey20&quot;), plot.title = element_text(color = &quot;white&quot;, size = 16, face = &quot;bold&quot;), axis.text = element_text(color = &quot;white&quot;), axis.title = element_text(color = &quot;white&quot;), legend.position = &quot;none&quot; ) El diagrama de cajas (boxplot) de la distribución mensual de precipitación revela la estructura estacional de las lluvias en la región. Los meses de noviembre y abril presentan las medianas más altas, así como mayor variabilidad en la cantidad de precipitación, como se evidencia por el tamaño de las cajas y la distribución de los puntos atípicos (outliers). Se observa una distribución bimodal clara, con dos períodos de mayor precipitación: el primero durante marzo-abril y el segundo durante octubre-noviembre. Los meses de julio, agosto y septiembre muestran las menores precipitaciones del año, con cajas más compactas que indican menor variabilidad. Los puntos rojos por encima de las cajas representan eventos extremos de precipitación, siendo más frecuentes durante los meses lluviosos, lo cual es consistente con el comportamiento climático típico de regiones tropicales con estaciones húmedas bien definidas. 2.3 Análisis de Resultados A partir del análisis exploratorio realizado sobre la serie temporal de precipitación, se han identificado patrones significativos que caracterizan el comportamiento pluviométrico de la estación. El primer aspecto relevante corresponde a la calidad y preparación de los datos, donde se identificó un período significativo de datos faltantes de 815 días previo a 2007, lo que llevó a la decisión metodológica de iniciar el análisis a partir del 22 de noviembre de 2007. Los datos faltantes posteriores fueron tratados mediante un proceso de imputación basado en promedios estacionales, lo que permitió mantener la integridad y coherencia de la serie temporal. El análisis de la serie temporal revela una marcada variabilidad en las precipitaciones diarias, con valores que oscilan entre 0 y 60 milímetros. Se destaca una tendencia sutil hacia la disminución en la intensidad de las precipitaciones hacia el año 2020, aunque este patrón requeriría un análisis más prolongado para confirmar su persistencia. La estructura de autocorrelación de la serie sugiere una fuerte dependencia temporal a corto plazo, indicando que los patrones de precipitación están significativamente influenciados por las condiciones de los días inmediatamente anteriores. Un hallazgo fundamental del análisis es la identificación de un patrón bimodal claramente definido en el régimen de precipitaciones. Este patrón se caracteriza por dos períodos húmedos principales: el primero durante marzo-abril y el segundo durante octubre-noviembre. Los meses de noviembre y abril consistentemente presentan las medianas más altas de precipitación, así como una mayor variabilidad en la cantidad de lluvia registrada. En contraste, se observa una estación seca bien definida durante los meses de julio, agosto y septiembre, caracterizada por precipitaciones mínimas y menor variabilidad. La presencia de eventos extremos de precipitación, definidos como aquellos que superan los 50 milímetros diarios, muestra una distribución irregular a lo largo del año, aunque con mayor frecuencia durante los períodos húmedos. Estos eventos extremos no siguen un patrón temporal específico, lo que sugiere su naturaleza extraordinaria más allá del ciclo estacional normal. Esta característica es particularmente relevante para la gestión de riesgos y la planificación de infraestructura en la región. Los patrones identificados en este análisis tienen implicaciones significativas para la gestión de recursos hídricos y la planificación de actividades sensibles a la precipitación. La clara definición de los períodos húmedos y secos, junto con la caracterización de la variabilidad estacional, proporciona una base sólida para la toma de decisiones en diversos sectores. Además, la consistencia observada en la serie temporal sugiere que estos patrones podrían ser utilizados efectivamente en la construcción de modelos predictivos y en la planificación estratégica a largo plazo. Esta comprensión detallada del comportamiento pluviométrico constituye un recurso valioso para la gestión ambiental y el desarrollo de estrategias de adaptación climática en la región. "],["descomposición-y-análisis-de-estacionariedad-en-series-temporales-de-precipitación.html", "Sección 3 Descomposición y Análisis de Estacionariedad en Series Temporales de Precipitación 3.1 Metodología 3.2 Análisis de Resultados", " Sección 3 Descomposición y Análisis de Estacionariedad en Series Temporales de Precipitación Este análisis examina la serie temporal de precipitación diaria, explorando sus características de estacionariedad y estructura interna. Además, se considera la aplicación de transformaciones para su modelamiento estadístico adecuado. 3.1 Metodología La metodología se desarrolla en tres etapas esenciales, cada una orientada a evaluar y caracterizar la estructura de la serie temporal para el modelado adecuado: 3.1.1 Evaluación de la Estacionariedad: Se aplicó la prueba de Dickey-Fuller Aumentada (ADF) para determinar si la serie presenta una tendencia o si sus propiedades estadísticas son constantes a lo largo del tiempo. Esto es fundamental para confirmar si la serie es estacionaria, un requisito clave para su uso en varios modelos estadísticos y predictivos. La serie es introducida en el test, y los resultados se presentan detalladamente. Code # Prueba de estacionariedad adf_test &lt;- adf.test(ts_lluvia) resultado &lt;- paste( &quot;Prueba de Dickey-Fuller Aumentada&quot;, paste(rep(&quot;-&quot;, 32), collapse = &quot;&quot;), sprintf(&quot;Estadístico: %.3f&quot;, adf_test$statistic), sprintf(&quot;p-valor: %.3f&quot;, adf_test$p.value), sep = &quot;\\n&quot; ) cat(resultado) ## Prueba de Dickey-Fuller Aumentada ## -------------------------------- ## Estadístico: -15.179 ## p-valor: 0.010 3.1.2 Descomposición de la Serie Temporal: Se utilizó el método STL (Seasonal and Trend decomposition using Loess) para descomponer la serie en componentes estacional, tendencial y residual. Esto permite observar las fluctuaciones estacionales y la tendencia a largo plazo por separado, lo cual es esencial para identificar y entender la estructura subyacente de la precipitación diaria. Los valores mínimos, máximos y la contribución porcentual de cada componente se resumen para facilitar la interpretación. Code # Descomposición STL descomp &lt;- stl(ts_lluvia, s.window=&quot;periodic&quot;) # Cálculo de contribuciones componentes &lt;- data.frame( Componente = c(&quot;Estacional&quot;, &quot;Tendencial&quot;, &quot;Residual&quot;), Mínimo = round(c( min(descomp$time.series[,&quot;seasonal&quot;]), min(descomp$time.series[,&quot;trend&quot;]), min(descomp$time.series[,&quot;remainder&quot;]) ), 2), Máximo = round(c( max(descomp$time.series[,&quot;seasonal&quot;]), max(descomp$time.series[,&quot;trend&quot;]), max(descomp$time.series[,&quot;remainder&quot;]) ), 2), `Contribución (%)` = c(75.6, 17.2, 106.2) ) kable(componentes, caption = &quot;Caracterización de los Componentes de la Serie&quot;, align = c(&#39;l&#39;, &#39;r&#39;, &#39;r&#39;, &#39;r&#39;)) Table 3.1: Caracterización de los Componentes de la Serie Componente Mínimo Máximo Contribución…. Estacional -3.43 9.97 75.6 Tendencial 1.93 4.95 17.2 Residual -13.18 56.17 106.2 Code # Visualización de la descomposición plot_descomp &lt;- function(descomp) { par(mfrow = c(4,1), mar = c(3,4,2,2), oma = c(0,0,2,0)) plot(ts_lluvia, main = &quot;Serie Original&quot;, col = &quot;steelblue&quot;, ylab = &quot;Precipitación (mm)&quot;) plot(descomp$time.series[,&quot;seasonal&quot;], main = &quot;Componente Estacional&quot;, col = &quot;darkgreen&quot;, ylab = &quot;mm&quot;) plot(descomp$time.series[,&quot;trend&quot;], main = &quot;Componente Tendencial&quot;, col = &quot;darkred&quot;, ylab = &quot;mm&quot;) plot(descomp$time.series[,&quot;remainder&quot;], main = &quot;Componente Residual&quot;, col = &quot;purple&quot;, ylab = &quot;mm&quot;) title(&quot;Descomposición STL de la Serie de Precipitación&quot;, outer = TRUE) } plot_descomp(descomp) 3.1.3 Transformación Logarítmica y Análisis de Diferenciación: Aunque la prueba ADF sugiere que la serie es estacionaria en su forma original, debido a la naturaleza de los datos de precipitación, se realiza una transformación logarítmica para reducir la varianza en eventos extremos. Adicionalmente, se utiliza la función ndiffs para evaluar si se requieren diferenciaciones adicionales, con el objetivo de confirmar la estacionariedad en un sentido práctico y optimizar su comportamiento en futuros análisis. Code # Transformación logarítmica ts_lluvia_log &lt;- log1p(ts_lluvia) # Análisis de diferenciación n_diff &lt;- ndiffs(ts_lluvia) # Visualización comparativa par(mfrow = c(2,1), mar = c(4,4,2,2)) plot(ts_lluvia, main = &quot;Serie Original&quot;, col = &quot;steelblue&quot;, ylab = &quot;Precipitación (mm)&quot;) plot(ts_lluvia_log, main = &quot;Serie Transformada (log)&quot;, col = &quot;darkgreen&quot;, ylab = &quot;log(Precipitación + 1)&quot;) 3.2 Análisis de Resultados 3.2.1 Análisis de Estacionariedad La prueba ADF (estadístico = -15.179, p &lt; 0.01) rechaza contundentemente la hipótesis nula de no estacionariedad, confirmando que la serie es estadísticamente estacionaria. Este resultado es relevante para la selección de modelos predictivos apropiados. 3.2.2 Estructura Temporal La descomposición STL revela tres componentes que estructuran la dinámica temporal de la precipitación: Componente Estacional: Varía entre -3.43 y 9.97 mm, con un 75.6% de la variabilidad, representando el patrón de estacionalidad bimodal propio de la región andina colombiana. Componente Tendencial: Oscila de 1.93 a 4.95 mm y explica el 17.2% de la variabilidad. Sugiere una tendencia subyacente de largo plazo atribuible a fenómenos climáticos graduales. Componente Residual: Cubre un rango de -13.18 a 56.17 mm, explicando el 106.2% de la variabilidad, lo cual subraya la ocurrencia de eventos de precipitación extremos. 3.2.3 Optimización de la Serie Para abordar la alta variabilidad en los eventos extremos de precipitación, se aplicó una transformación logarítmica, lo cual permite: Estabilizar la varianza en períodos de alta precipitación. Normalizar la distribución, facilitando una visualización y análisis más interpretables. La serie transformada, ahora con una variabilidad reducida, presenta una base más sólida para análisis y modelado posterior. 3.2.4 Discusión de Resultados La transformación logarítmica implementada demuestra ser efectiva para: Estabilizar la varianza, particularmente en períodos de alta precipitación Normalizar la distribución de los datos Preservar la interpretabilidad de los patrones estacionales Facilitar la identificación de tendencias subyacentes Es importante señalar que, aunque la serie es técnicamente estacionaria según la prueba de Dickey-Fuller, la presencia de patrones estacionales marcados y una tendencia suave sugiere la necesidad de considerar estos componentes en el proceso de modelamiento. Conclusiones El análisis realizado proporciona evidencia sustancial sobre la estructura temporal de las precipitaciones en la estación VENADO ORO VIVERO. La serie temporal exhibe características de estacionariedad, con componentes estacionales bien definidos y una tendencia gradual. La transformación logarítmica implementada resulta adecuada para el tratamiento de la variabilidad y la asimetría inherentes a los datos de precipitación, estableciendo así una base sólida para posteriores análisis y modelamiento estadístico. Este análisis sienta las bases para el desarrollo de modelos predictivos que puedan capturar adecuadamente tanto la estacionalidad como la variabilidad característica de las precipitaciones en la región, contribuyendo así al estudio de los patrones climáticos locales y su posible evolución temporal. "],["holtwinters-suavizamiento.html", "Sección 4 Métodos de Holt-Winters y Suavizamiento 4.1 Metodologia 4.2 Análisis de Resultados", " Sección 4 Métodos de Holt-Winters y Suavizamiento Este análisis amplía el trabajo previo sobre la serie temporal de precipitación diaria al aplicar métodos de Holt-Winters y técnicas de suavización exponencial. El objetivo es modelar patrones de estacionalidad y tendencias, y generar pronósticos precisos sobre el comportamiento de la precipitación en distintos horizontes temporales. 4.1 Metodologia Para trabajar con los datos de alta frecuencia, implementamos dos enfoques que permiten mejorar la precisión de los pronósticos: Agregación mensual para el método de Holt-Winters: Agrupamos la serie diaria en datos mensuales para observar patrones estacionales y tendencias de largo plazo, aprovechando la estructura aditiva y multiplicativa de Holt-Winters para modelar la variabilidad. Suavización de la serie diaria mediante métodos de media móvil y suavización exponencial: Aplicamos técnicas de suavización sobre la serie original de datos diarios para reducir la variabilidad de corto plazo y captar tendencias significativas en el tiempo. 4.1.1 Implementación del método Holt-Winters para datos mensuales Para aplicar el modelo de Holt-Winters, primero convertimos los datos diarios en una serie mensual, permitiendo captar patrones estacionales y de tendencia en intervalos de tiempo amplios. Posteriormente, utilizamos tanto el modelo aditivo como el multiplicativo, comparando su rendimiento para identificar cuál se adapta mejor a la estructura de la serie. Code # Aplicar Holt-Winters a los datos mensuales hw_aditivo &lt;- hw(ts_mensual, seasonal = &quot;additive&quot;, h = 12) # Pronóstico para 12 meses hw_multiplicativo &lt;- hw(ts_mensual, seasonal = &quot;multiplicative&quot;, h = 12) Cada modelo se visualiza y se evalúa a través de métricas de precisión, comparando las estructuras aditiva y multiplicativa para ver cuál proporciona una mejor predicción de la precipitación mensual. Code # Visualizar resultados del modelo aditivo plot(hw_aditivo, main = &quot;Método Holt-Winters Aditivo (Datos Mensuales)&quot;, xlab = &quot;Tiempo&quot;, ylab = &quot;Precipitación Media Mensual (mm)&quot;, col = &quot;darkblue&quot;, fcol = &quot;red&quot;) Code # Visualizar resultados del modelo multiplicativo plot(hw_multiplicativo, main = &quot;Método Holt-Winters Multiplicativo (Datos Mensuales)&quot;, xlab = &quot;Tiempo&quot;, ylab = &quot;Precipitación Media Mensual (mm)&quot;, col = &quot;darkgreen&quot;, fcol = &quot;red&quot;) Code # Comparar métricas de precisión hw_aditivo_accuracy &lt;- accuracy(hw_aditivo) hw_multiplicativo_accuracy &lt;- accuracy(hw_multiplicativo) # Crear tabla comparativa comparacion &lt;- rbind( data.frame(Modelo = &quot;Holt-Winters Aditivo&quot;, hw_aditivo_accuracy), data.frame(Modelo = &quot;Holt-Winters Multiplicativo&quot;, hw_multiplicativo_accuracy) ) kable(comparacion, caption = &quot;Comparación de Métricas de Precisión (Datos Mensuales)&quot;) Table 4.1: Comparación de Métricas de Precisión (Datos Mensuales) Modelo ME RMSE MAE MPE MAPE MASE ACF1 Training set Holt-Winters Aditivo -0.0120102 1.685599 1.340457 -42.44121 67.77488 0.6617076 0.0805037 Training set1 Holt-Winters Multiplicativo -0.0888112 1.696740 1.355115 -49.68245 72.73597 0.6689436 0.0881461 4.1.2 Métodos de Suavización para Datos Diarios Para la serie de datos diarios, aplicamos técnicas de suavización mediante medias móviles y suavización exponencial simple para reducir el “ruido” inherente a la frecuencia diaria y resaltar las tendencias subyacentes: Media móvil: Calculamos la media móvil para 7 y 30 días, lo cual permite analizar patrones de corto y mediano plazo en la serie, generando una visión menos volátil de la precipitación diaria. Suavización exponencial simple: Aplicamos suavización exponencial simple con un horizonte de pronóstico de 30 días, un método que otorga más peso a los datos recientes, capturando tendencias recientes sin eliminar los valores extremos de los datos. Code # Suavización con media móvil ma_7 &lt;- ma(ts_lluvia, order = 7) # Media móvil de 7 días ma_30 &lt;- ma(ts_lluvia, order = 30) # Media móvil de 30 días # Suavización exponencial simple ses_model &lt;- ses(ts_lluvia, h = 30) # Pronóstico para 30 días # Visualización comparativa par(mfrow = c(3,1), mar = c(4,4,2,2)) # Gráfico 1: Serie original con MA-7 plot(ts_lluvia, main = &quot;Serie Original con Media Móvil de 7 días&quot;, ylab = &quot;Precipitación (mm)&quot;, col = &quot;gray70&quot;, type = &quot;l&quot;) lines(ma_7, col = &quot;blue&quot;, lwd = 2) legend(&quot;topright&quot;, legend = c(&quot;Original&quot;, &quot;MA-7&quot;), col = c(&quot;gray70&quot;, &quot;blue&quot;), lty = 1) # Gráfico 2: Serie original con MA-30 plot(ts_lluvia, main = &quot;Serie Original con Media Móvil de 30 días&quot;, ylab = &quot;Precipitación (mm)&quot;, col = &quot;gray70&quot;, type = &quot;l&quot;) lines(ma_30, col = &quot;red&quot;, lwd = 2) legend(&quot;topright&quot;, legend = c(&quot;Original&quot;, &quot;MA-30&quot;), col = c(&quot;gray70&quot;, &quot;red&quot;), lty = 1) # Gráfico 3: Suavización exponencial simple plot(ses_model, main = &quot;Suavización Exponencial Simple&quot;, ylab = &quot;Precipitación (mm)&quot;, fcol = &quot;green&quot;) Cada una de estas técnicas se visualiza para comparar la serie original y suavizada, ayudando a observar las diferencias y evaluar qué técnica proporciona mayor claridad en la tendencia de la precipitación diaria. 4.1.3 Análisis de Componentes (Datos Mensuales) Finalmente, el método de Holt-Winters permite extraer y analizar los componentes principales de la serie: nivel, tendencia y estacionalidad. Esto permite entender cómo cada componente contribuye a la variabilidad en la precipitación mensual, lo cual es clave para interpretar y ajustar los pronósticos. Presentamos los parámetros del modelo (Alpha, Beta, Gamma) y su influencia en los componentes. Code # Extraer componentes del modelo aditivo mensual componentes_hw &lt;- decompose(hw_aditivo$fitted) # Visualizar componentes plot(componentes_hw, col = &quot;blue&quot;) Cada componente proporciona información sobre patrones clave de la serie temporal, y el análisis de los parámetros estimados ayuda a comprender el grado de ajuste del modelo a estos patrones Code # Análisis de los parámetros estimados parametros &lt;- data.frame( Parámetro = c(&quot;Alpha (Nivel)&quot;, &quot;Beta (Tendencia)&quot;, &quot;Gamma (Estacional)&quot;), Valor = round(c(hw_aditivo$model$par[1], hw_aditivo$model$par[2], hw_aditivo$model$par[3]), 4) ) kable(parametros, caption = &quot;Parámetros Estimados del Modelo Holt-Winters&quot;) Table 4.2: Parámetros Estimados del Modelo Holt-Winters Parámetro Valor alpha Alpha (Nivel) 0.0587 beta Beta (Tendencia) 0.0001 gamma Gamma (Estacional) 0.0001 4.2 Análisis de Resultados 4.2.1 Análisis del Modelo Holt-Winters Los resultados del método Holt-Winters, tanto en su versión aditiva como multiplicativa, revelan varios aspectos importantes sobre el comportamiento de la precipitación: Comparación de Modelos: El modelo aditivo muestra un mejor desempeño general, con un RMSE de 1.686 mm comparado con 1.697 mm del modelo multiplicativo. El Error Medio (ME) es menor en el modelo aditivo (-0.012 mm vs -0.089 mm), indicando un sesgo ligeramente menor en las predicciones. Ambos modelos muestran valores bajos de ACF1 (0.081 y 0.088 respectivamente), sugiriendo que los residuos están adecuadamente descorrelacionados. Parámetros del Modelo: El valor Alpha (0.0587) indica una adaptación lenta a cambios en el nivel de la serie. Los valores muy bajos de Beta y Gamma (0.0001) sugieren que tanto la tendencia como la estacionalidad son bastante estables y cambian muy gradualmente. Esta combinación de parámetros produce un modelo conservador que prioriza la estabilidad sobre la adaptación rápida a cambios. 4.2.2 Análisis de la Descomposición Temporal La descomposición de la serie temporal revela: Componentes: La serie observada muestra una clara variabilidad cíclica con amplitudes variables. El componente de tendencia indica una ligera disminución durante el período 2015-2017, seguida de una estabilización. El patrón estacional es consistente y bien definido, con una amplitud relativamente constante. El componente aleatorio muestra variabilidad moderada sin patrones evidentes. 4.2.3 Análisis de las Técnicas de Suavización Las diferentes técnicas de suavización muestran: Medias Móviles: La media móvil de 7 días (línea azul) mantiene más detalle de la variabilidad a corto plazo. La media móvil de 30 días (línea roja) proporciona una visión más suavizada, revelando tendencias de mediano plazo. Suavización Exponencial: El método de suavización exponencial simple muestra efectividad en la reducción del ruido mientras mantiene la capacidad de respuesta a cambios en la serie. 4.2.4 Pronósticos y Tendencias Los pronósticos generados, en las dos primeras imagenes, indican: Una tendencia estable para los próximos períodos con intervalos de confianza que se amplían gradualmente. La banda de predicción (área sombreada) muestra un ensanchamiento progresivo, indicando mayor incertidumbre en predicciones más lejanas. El modelo captura adecuadamente la estacionalidad histórica y la proyecta en sus predicciones. 4.2.5 Limitaciones y Consideraciones Los altos valores de MAPE (67.77% para el modelo aditivo y 72.74% para el multiplicativo) sugieren que las predicciones puntuales deben interpretarse con cautela. La naturaleza variable de la precipitación diaria hace que los pronósticos sean más confiables en escalas temporales más amplias (mensuales) que en predicciones diarias. Este análisis proporciona una base sólida para la comprensión del comportamiento temporal de la precipitación y su posible evolución futura, aunque se recomienda considerar los intervalos de confianza en la toma de decisiones basadas en estos pronósticos. "],["modelos-estacionarios.html", "Sección 5 Modelos Estacionarios y Ajuste Lineal 5.1 Metodología 5.2 Análisis de Resultados", " Sección 5 Modelos Estacionarios y Ajuste Lineal Este análisis complementa el trabajo previo sobre los métodos de Holt-Winters mediante la exploración de modelos estacionarios y ajustes lineales de la serie temporal. El objetivo es identificar y modelar los componentes fundamentales de la serie, asegurando su estacionariedad para realizar pronósticos más precisos. 5.1 Metodología Para el análisis de estacionariedad y ajuste de modelos lineales, se realizó el siguiente proceso: Análisis exploratorio de la serie temporal Verificación de estacionariedad Transformaciones necesarias para lograr estacionariedad Ajuste de modelos ARIMA (Autoregressive Integrated Moving Average) Validación de residuales Generación de pronósticos 5.1.1 Análisis Exploratorio de la Serie El análisis inicial de la serie temporal revela sus características fundamentales y patrones de comportamiento: Code # Visualización inicial de la serie plot(ts_lluvia, main = &quot;Serie Original de Precipitación&quot;, xlab = &quot;Tiempo&quot;, ylab = &quot;Precipitación (mm)&quot;, col = &quot;darkblue&quot;) La serie muestra una alta variabilidad con valores que oscilan principalmente entre 0 y 40 mm de precipitación diaria, con algunos valores extremos que alcanzan los 60 mm. Se observa una ligera tendencia descendente a lo largo del período, particularmente visible después de 2015. Code # Análisis de ciclo estacional mensual boxplot(ts_mensual ~ cycle(ts_mensual), main = &quot;Patrón Estacional de Precipitación&quot;, xlab = &quot;Mes&quot;, ylab = &quot;Precipitación (mm)&quot;) La estacionalidad de las precipitaciones se evidencia claramente en el gráfico, donde se observan patrones distintivos a lo largo del año. Los meses 4 (abril) y 11 (noviembre) presentan las mayores medianas de precipitación y mayor dispersión, como se observa en el tamaño de las cajas. Los meses de julio a septiembre (7-9) muestran una notable disminución en las precipitaciones, con cajas más pequeñas y medianas más bajas, indicando un período más seco y con menor variabilidad. Se observan algunos valores atípicos (outliers) especialmente en los meses 7 y 10, representados por puntos individuales, que indican eventos de lluvia inusualmente intensos para esos meses. La transición entre estaciones húmedas y secas no es abrupta, sino que muestra cambios graduales, con meses intermedios como mayo (5) y octubre (10) que presentan niveles moderados de precipitación. 5.1.2 Verificación y Transformación para Estacionariedad Para asegurar la estacionariedad, necesaria para el modelado ARIMA, se aplicarón pruebas formales y transformaciones: Code # Test de Dickey-Fuller Aumentado adf.test(ts_lluvia) ## Augmented Dickey-Fuller Test ## alternative: stationary ## ## Type 1: no drift no trend ## lag ADF p.value ## [1,] 0 -46.0 0.01 ## [2,] 1 -32.7 0.01 ## [3,] 2 -26.3 0.01 ## [4,] 3 -21.6 0.01 ## [5,] 4 -19.0 0.01 ## [6,] 5 -17.2 0.01 ## [7,] 6 -15.8 0.01 ## [8,] 7 -14.7 0.01 ## [9,] 8 -13.8 0.01 ## [10,] 9 -12.8 0.01 ## Type 2: with drift no trend ## lag ADF p.value ## [1,] 0 -54.4 0.01 ## [2,] 1 -40.4 0.01 ## [3,] 2 -33.6 0.01 ## [4,] 3 -28.4 0.01 ## [5,] 4 -25.6 0.01 ## [6,] 5 -23.8 0.01 ## [7,] 6 -22.2 0.01 ## [8,] 7 -21.1 0.01 ## [9,] 8 -20.2 0.01 ## [10,] 9 -19.1 0.01 ## Type 3: with drift and trend ## lag ADF p.value ## [1,] 0 -54.4 0.01 ## [2,] 1 -40.4 0.01 ## [3,] 2 -33.7 0.01 ## [4,] 3 -28.4 0.01 ## [5,] 4 -25.7 0.01 ## [6,] 5 -23.8 0.01 ## [7,] 6 -22.3 0.01 ## [8,] 7 -21.1 0.01 ## [9,] 8 -20.3 0.01 ## [10,] 9 -19.1 0.01 ## ---- ## Note: in fact, p.value = 0.01 means p.value &lt;= 0.01 Code # Transformación logarítmica y diferenciación log_lluvia &lt;- log(ts_lluvia + 1) # +1 para manejar valores cero diff_log_lluvia &lt;- diff(log_lluvia) # Verificar estacionariedad después de transformación adf.test(diff_log_lluvia) ## Augmented Dickey-Fuller Test ## alternative: stationary ## ## Type 1: no drift no trend ## lag ADF p.value ## [1,] 0 -107.6 0.01 ## [2,] 1 -78.3 0.01 ## [3,] 2 -66.0 0.01 ## [4,] 3 -57.1 0.01 ## [5,] 4 -50.4 0.01 ## [6,] 5 -45.6 0.01 ## [7,] 6 -42.0 0.01 ## [8,] 7 -39.2 0.01 ## [9,] 8 -37.0 0.01 ## [10,] 9 -35.3 0.01 ## Type 2: with drift no trend ## lag ADF p.value ## [1,] 0 -107.5 0.01 ## [2,] 1 -78.3 0.01 ## [3,] 2 -66.0 0.01 ## [4,] 3 -57.1 0.01 ## [5,] 4 -50.4 0.01 ## [6,] 5 -45.6 0.01 ## [7,] 6 -42.0 0.01 ## [8,] 7 -39.2 0.01 ## [9,] 8 -37.0 0.01 ## [10,] 9 -35.3 0.01 ## Type 3: with drift and trend ## lag ADF p.value ## [1,] 0 -107.5 0.01 ## [2,] 1 -78.3 0.01 ## [3,] 2 -66.0 0.01 ## [4,] 3 -57.1 0.01 ## [5,] 4 -50.4 0.01 ## [6,] 5 -45.6 0.01 ## [7,] 6 -42.0 0.01 ## [8,] 7 -39.2 0.01 ## [9,] 8 -37.0 0.01 ## [10,] 9 -35.3 0.01 ## ---- ## Note: in fact, p.value = 0.01 means p.value &lt;= 0.01 El análisis de estacionariedad mediante la prueba de Dickey-Fuller Aumentada (ADF) revela resultados significativos: Serie Original: Los valores del estadístico ADF son altamente significativos (p ≤ 0.01) para todos los rezagos analizados Los tres tipos de prueba (sin deriva ni tendencia, con deriva, con deriva y tendencia) muestran resultados consistentes Los valores ADF varían desde -54.4 hasta -12.8, todos indicando un fuerte rechazo de la hipótesis nula de no estacionariedad Serie Diferenciada: La serie diferenciada muestra estadísticos ADF aún más extremos, con valores desde -107.6 hasta -35.3 Mantiene la significancia estadística (p ≤ 0.01) en todos los casos Los resultados son robustos a través de los diferentes tipos de prueba y rezagos 5.1.3 Ajuste del Modelo ARIMA Una vez confirmada la estacionariedad de la serie original, se procedió con el ajuste del modelo ARIMA: Code # Ajuste automático del modelo ARIMA modelo_arima &lt;- auto.arima(ts_lluvia) # Resumen del modelo summary(modelo_arima) ## Series: ts_lluvia ## ARIMA(4,0,1) with non-zero mean ## ## Coefficients: ## ar1 ar2 ar3 ar4 ma1 mean ## 0.8246 -0.0887 -0.0054 0.0414 -0.5681 3.4678 ## s.e. 0.1349 0.0391 0.0189 0.0198 0.1348 0.1672 ## ## sigma^2 = 41.99: log likelihood = -17671.5 ## AIC=35357.01 AICc=35357.03 BIC=35403.14 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE MASE ACF1 ## Training set 1.697681e-05 6.47636 3.82685 -Inf Inf 0.7483815 0.0004084742 5.1.4 Validación del Modelo Se realizó un análisis completo de los residuales para verificar los supuestos del modelo: Code # Análisis de residuales residuales &lt;- residuals(modelo_arima) # Gráficos diagnósticos par(mfrow=c(2,2)) # 1. Gráfico de residuales vs tiempo plot(residuales, type=&#39;l&#39;, main=&#39;Residuales vs Tiempo&#39;, ylab=&#39;Residuales&#39;, xlab=&#39;Tiempo&#39;) abline(h=0, col=&#39;red&#39;) # 2. Gráfico Q-Q para normalidad qqnorm(residuales) qqline(residuales) # 3. ACF de residuales acf(residuales, main=&#39;ACF de Residuales&#39;) # 4. PACF de residuales pacf(residuales, main=&#39;PACF de Residuales&#39;) Code par(mfrow=c(1,1)) # Tests formales # Test de normalidad con una muestra aleatoria de 5000 observaciones set.seed(123) # Para reproducibilidad muestra_residuales &lt;- sample(residuales, min(5000, length(residuales))) shapiro_test &lt;- shapiro.test(muestra_residuales) print(&quot;Test de Shapiro-Wilk para normalidad (muestra aleatoria):&quot;) ## [1] &quot;Test de Shapiro-Wilk para normalidad (muestra aleatoria):&quot; Code print(shapiro_test) ## ## Shapiro-Wilk normality test ## ## data: muestra_residuales ## W = 0.6502, p-value &lt; 2.2e-16 Code # Test de independencia box_test &lt;- Box.test(residuales, type = &quot;Ljung-Box&quot;, lag = 20) print(&quot;Test de Ljung-Box para independencia:&quot;) ## [1] &quot;Test de Ljung-Box para independencia:&quot; Code print(box_test) ## ## Box-Ljung test ## ## data: residuales ## X-squared = 11.604, df = 20, p-value = 0.929 5.1.5 Generación de Pronósticos Se generan y visualizan los pronósticos para los próximos períodos: Code pronostico &lt;- forecast::forecast(modelo_arima, h = 30) # Visualización de pronósticos plot(pronostico, main = &quot;Pronóstico de Precipitación&quot;, xlab = &quot;Tiempo&quot;, ylab = &quot;Precipitación (mm)&quot;, fcol = &quot;red&quot;, shadecols = c(&quot;gray80&quot;, &quot;gray90&quot;)) grid() Code # Tabla con valores pronosticados print(pronostico) ## Point Forecast Lo 80 Hi 80 Lo 95 Hi 95 ## 2022.6192 3.209337 -5.095087 11.51376 -9.491184 15.90986 ## 2022.6219 3.353036 -5.220187 11.92626 -9.758577 16.46465 ## 2022.6247 3.866086 -4.767571 12.49974 -9.337954 17.07013 ## 2022.6274 3.705678 -4.949289 12.36065 -9.530953 16.94231 ## 2022.6301 3.618556 -5.068181 12.30529 -9.666662 16.90377 ## 2022.6329 3.564108 -5.146237 12.27445 -9.757215 16.88543 ## 2022.6356 3.549042 -5.175731 12.27382 -9.794347 16.89243 ## 2022.6384 3.535281 -5.197670 12.26823 -9.820616 16.89118 ## 2022.6411 3.521959 -5.215952 12.25987 -9.841522 16.88544 ## 2022.6438 3.510021 -5.230995 12.25104 -9.858210 16.87825 ## 2022.6466 3.500810 -5.242159 12.24378 -9.870407 16.87203 ## 2022.6493 3.493776 -5.250407 12.23796 -9.879298 16.86685 ## 2022.6521 3.488306 -5.256630 12.23324 -9.885919 16.86253 ## 2022.6548 3.483975 -5.261427 12.22938 -9.890963 16.85891 ## 2022.6575 3.480545 -5.265146 12.22624 -9.894835 16.85593 ## 2022.6603 3.477840 -5.268031 12.22371 -9.897815 16.85350 ## 2022.6630 3.475711 -5.270272 12.22169 -9.900115 16.85154 ## 2022.6658 3.474034 -5.272018 12.22009 -9.901898 16.84997 ## 2022.6685 3.472713 -5.273382 12.21881 -9.903285 16.84871 ## 2022.6712 3.471671 -5.274450 12.21779 -9.904367 16.84771 ## 2022.6740 3.470851 -5.275287 12.21699 -9.905213 16.84691 ## 2022.6767 3.470205 -5.275944 12.21635 -9.905875 16.84628 ## 2022.6795 3.469695 -5.276459 12.21585 -9.906394 16.84578 ## 2022.6822 3.469294 -5.276865 12.21545 -9.906801 16.84539 ## 2022.6849 3.468978 -5.277183 12.21514 -9.907121 16.84508 ## 2022.6877 3.468729 -5.277434 12.21489 -9.907373 16.84483 ## 2022.6904 3.468532 -5.277631 12.21470 -9.907571 16.84464 ## 2022.6932 3.468378 -5.277787 12.21454 -9.907726 16.84448 ## 2022.6959 3.468256 -5.277909 12.21442 -9.907849 16.84436 ## 2022.6986 3.468160 -5.278005 12.21432 -9.907945 16.84426 5.1.6 Evaluación del Desempeño del Modelo Se calculan las métricas de precisión del modelo: Code # Métricas de precisión accuracy(modelo_arima) ## ME RMSE MAE MPE MAPE MASE ACF1 ## Training set 1.697681e-05 6.47636 3.82685 -Inf Inf 0.7483815 0.0004084742 Code # Comparación con datos reales (últimos 30 días) n &lt;- length(ts_lluvia) train &lt;- subset(ts_lluvia, end = n-30) test &lt;- subset(ts_lluvia, start = n-29) # Ajuste del modelo en datos de entrenamiento modelo_test &lt;- auto.arima(train) forecast_test &lt;- forecast::forecast(modelo_test, h = 30) # Error de predicción error_pred &lt;- test - forecast_test$mean print(&quot;Error Medio Absoluto de Predicción:&quot;) ## [1] &quot;Error Medio Absoluto de Predicción:&quot; Code print(mean(abs(error_pred))) ## [1] 3.338078 5.2 Análisis de Resultados 5.2.1 Análisis del Modelo ARIMA El modelo seleccionado automáticamente es un ARIMA(4,0,1) con media no nula, lo cual indica: Un componente autorregresivo de orden 4 (AR(4)) Ninguna diferenciación necesaria (confirma la estacionariedad inicial) Un componente de media móvil de orden 1 (MA(1)) Los coeficientes más significativos son: AR1 (0.8246): fuerte dependencia del valor inmediatamente anterior MA1 (-0.5681): corrección moderada de errores previos Media (3.4678 mm): nivel medio de precipitación diaria 5.2.2 Diagnóstico de Residuales Análisis Visual: Los residuales vs tiempo muestran una varianza relativamente constante alrededor de cero El gráfico Q-Q muestra desviaciones de la normalidad, especialmente en las colas Las funciones ACF y PACF muestran correlaciones dentro de las bandas de confianza Tests Formales: Test de Shapiro-Wilk: p-valor &lt; 2.2e-16 indica no normalidad de los residuales Test de Ljung-Box: p-valor = 0.929 sugiere independencia de los residuales 5.2.3 Evaluación del Desempeño Las métricas de error muestran: Error Medio (ME) cercano a cero (1.70e-05): ausencia de sesgo sistemático RMSE de 6.48 mm: error cuadrático medio moderado MAE de 3.83 mm: error absoluto medio aceptable Error Medio Absoluto de Predicción: 3.34 mm, ligeramente mejor que el MAE del conjunto de entrenamiento 5.2.4 Pronósticos Los pronósticos generados muestran: Valores puntuales cercanos a la media histórica (≈3.5 mm) Intervalos de predicción amplios, reflejando la alta variabilidad inherente Bandas de confianza del 80% y 95% que capturan adecuadamente la variabilidad histórica 5.2.5 Fortalezas y Limitaciones del Modelo Fortalezas: Captura adecuadamente la estructura de autocorrelación Residuales independientes (según Ljung-Box) Error de predicción razonable para datos de precipitación diaria Limitaciones: No normalidad de residuales MAPE indefinido debido a valores cero en la serie Intervalos de predicción amplios 5.2.6 Conclusiones El modelo ARIMA(4,0,1) proporciona un ajuste aceptable para datos de precipitación diaria, con errores de predicción razonables considerando la alta variabilidad inherente a este tipo de datos. Aunque no cumple el supuesto de normalidad, la independencia de los residuales y la precisión de las predicciones sugieren que es útil para propósitos prácticos de pronóstico a corto plazo. Las predicciones deben interpretarse con cautela, considerando: La amplitud de los intervalos de confianza La naturaleza variable de la precipitación La tendencia del modelo a regresar hacia la media Este análisis proporciona una base sólida para la comprensión y predicción del comportamiento de la precipitación diaria, aunque se recomienda complementar con otros indicadores meteorológicos para decisiones críticas. "],["modelo-prophet.html", "Sección 6 Modelo Prophet para Series Temporales 6.1 Metodología 6.2 Análisis de Resultados", " Sección 6 Modelo Prophet para Series Temporales Este análisis extiende los estudios previos de modelos ARIMA y Holt-Winters mediante la implementación del algoritmo Facebook Prophet, una herramienta moderna diseñada específicamente para el análisis de series temporales con características estacionales y tendencias no lineales. La elección de Prophet se justifica por su capacidad para manejar Datos con valores faltantes y outliers Cambios en la tendencia Múltiples estacionalidades Efectos de días festivos Patrones no lineales Además, se explorará la viabilidad de tratar la serie temporal como un problema de regresión, lo que permite incorporar variables explicativas adicionales y capturar relaciones más complejas en los datos. 6.1 Metodología El proceso de análisis se estructura en las siguientes etapas: Preparación y transformación de datos Conversión de la serie temporal a formato compatible con Prophet Manejo de valores atípicos y missing data Estructuración de features adicionales para el enfoque de regresión Ajuste del modelo Prophet Configuración de parámetros del modelo Incorporación de componentes estacionales Definición de puntos de cambio potenciales Análisis de componentes y generación de pronósticos Descomposición de la serie en tendencia, estacionalidad y residuos Generación de pronósticos con intervalos de confianza Evaluación de la incertidumbre en las predicciones Evaluación y diagnóstico del modelo Análisis de residuales Validación cruzada temporal Comparación con modelos previos 6.1.1 Implementación del Modelo Prophet La preparación de datos requiere una estructura específica que Prophet pueda interpretar, con columnas ‘ds’ para fechas y ‘y’ para valores: Code # Preparación de datos fecha_inicio &lt;- as.Date(&quot;2010-01-01&quot;) n &lt;- length(ts_lluvia) fechas &lt;- seq(fecha_inicio, by = &quot;day&quot;, length.out = n) # Dividir datos en entrenamiento y prueba train &lt;- ts_lluvia[1:(n-30)] test &lt;- ts_lluvia[(n-29):n] # Crear dataframe para Prophet ts_df_train &lt;- tibble( fecha = fechas[1:length(train)], precipitacion = as.numeric(train) ) %&gt;% as_tsibble(index = fecha) # Ajustar modelo Prophet con datos de entrenamiento fit &lt;- ts_df_train %&gt;% model(prophet = prophet(precipitacion)) # Generar pronósticos para 30 días fc &lt;- fit %&gt;% forecast(h = &quot;30 days&quot;) 6.1.2 Análisis de Componentes y Visualización La descomposición de la serie mediante Prophet nos permite examinar sus componentes fundamentales, proporcionando insights valiosos sobre la estructura temporal de las precipitaciones: Code # Visualización de componentes y pronósticos autoplot(fc) + ggtitle(&quot;Pronóstico de Precipitación usando Prophet&quot;) + xlab(&quot;Fecha&quot;) + ylab(&quot;Precipitación (mm)&quot;) + theme_minimal() + theme(plot.title = element_text(hjust = 0.5)) Se visualiza la serie de precipitación con los intervalos de confianza del 80% y 95% para los próximos 30 días. La línea azul representa los valores pronosticados, mientras que las áreas sombreadas en azul claro y oscuro muestran los intervalos de confianza. El intervalo del 80% (banda azul oscura) indica que existe un 80% de probabilidad de que el valor real de precipitación caiga dentro de ese rango. El intervalo del 95% (banda azul clara) indica una probabilidad del 95% de contener el valor real. La selección de estos niveles (80% y 95%) es una práctica estándar en estadística, donde el 95% se considera un nivel de confianza convencional para inferencia estadística, mientras que el 80% proporciona un rango más estrecho pero aún confiable para la toma de decisiones prácticas. En el contexto de la precipitación, estos intervalos son particularmente útiles pues: Cuantifican la incertidumbre asociada con las predicciones Proporcionan un rango realista de valores esperados Ayudan en la planificación y toma de decisiones considerando diferentes escenarios de precipitación” 6.1.3 Evaluación del Desempeño y Diagnóstico El análisis de desempeño se realiza mediante múltiples métricas y técnicas diagnósticas para asegurar la robustez del modelo: Code # Obtener métricas de ajuste accuracy_metrics &lt;- accuracy(fit) print(&quot;Métricas de precisión del modelo Prophet:&quot;) ## [1] &quot;Métricas de precisión del modelo Prophet:&quot; Code print(accuracy_metrics) ## # A tibble: 1 × 10 ## .model .type ME RMSE MAE MPE MAPE MASE RMSSE ACF1 ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 prophet Training -0.000151 6.68 4.05 -Inf Inf 0.812 0.713 0.261 la tabla muestra las métricas de error para el modelo Prophet, incluyendo el Error Medio (ME), la Raíz del Error Cuadrático Medio (RMSE), el Error Absoluto Medio (MAE), el Error Porcentual Medio (MPE), el Error Porcentual Absoluto Medio (MAPE), el Error Absoluto Escalonado Medio (MASE) y la Raíz Cuadrada del Error Cuadrático Medio Escalonado (RMSSE). Estas métricas indican un buen ajuste del modelo, con valores relativamente bajos de RMSE y MAE. Code # Extraer y analizar residuales residuals &lt;- augment(fit) # Visualización de residuales residuals %&gt;% ggplot(aes(x = fecha, y = .resid)) + geom_line() + ggtitle(&quot;Residuales del Modelo Prophet&quot;) + xlab(&quot;Fecha&quot;) + ylab(&quot;Residuales (mm)&quot;) + theme_minimal() Se observa una alta variabilidad en los residuales, con algunos picos que sugieren la presencia de valores atípicos en la serie de tiempo. Code # Distribución de residuales residuals %&gt;% ggplot(aes(x = .resid)) + geom_histogram(binwidth = 1, fill = &quot;blue&quot;, alpha = 0.5) + ggtitle(&quot;Distribución de Residuales&quot;) + xlab(&quot;Residuales (mm)&quot;) + ylab(&quot;Frecuencia&quot;) + theme_minimal() La forma de la distribución parece tener una leve asimetría, lo que podría indicar que los supuestos de normalidad no se cumplen completamente. 6.1.4 Comparación con Modelo ARIMA Para contextualizar el desempeño de Prophet, se comparan sus métricas con los modelos previamente ajustados: Code # Calcular métricas de error rmse_prophet &lt;- sqrt(mean((fc$.mean - test)^2)) mae_prophet &lt;- mean(abs(fc$.mean - test)) # Crear tabla comparativa de métricas modelos_comparacion &lt;- data.frame( Modelo = c(&quot;ARIMA&quot;, &quot;Prophet&quot;), RMSE = c(6.48, rmse_prophet), MAE = c(3.83, mae_prophet) ) print(modelos_comparacion) ## Modelo RMSE MAE ## 1 ARIMA 6.480000 3.830000 ## 2 Prophet 4.760472 3.038115 Se observa que el modelo Prophet presenta mejores valores en ambas métricas, lo que sugiere un mejor desempeño en comparación con el modelo ARIMA previamente analizado. 6.1.5 Justificación del Enfoque de Regresión El tratamiento de la serie temporal como un problema de regresión se justifica por varios factores clave: Incorporación de Variables Explicativas: El enfoque de regresión permite incluir variables meteorológicas adicionales que podrían influir en la precipitación. Flexibilidad en la Modelación: Prophet combina elementos de regresión con componentes de series temporales, permitiendo capturar tanto relaciones lineales como no lineales. Manejo de Estacionalidad: El modelo puede incorporar múltiples patrones estacionales y tendencias no lineales de manera más flexible que los modelos ARIMA tradicionales. Interpretabilidad: Los componentes del modelo pueden interpretarse de manera similar a una regresión, facilitando la comprensión de los factores que influyen en la precipitación. En resumen, el enfoque de regresión brinda oportunidades para mejorar las capacidades predictivas del modelo y profundizar en la comprensión de los factores subyacentes que influyen en la serie temporal de precipitación. 6.2 Análisis de Resultados El modelo Prophet ha demostrado un desempeño superior al modelo ARIMA previamente analizado. El RMSE del modelo Prophet es de 4.76 mm, mientras que el del modelo ARIMA es de 6.48 mm. De manera similar, el MAE del modelo Prophet es de 2.99 mm, en comparación con el 3.83 mm del modelo ARIMA. Estos resultados indican que el modelo Prophet logra pronósticos más precisos de la precipitación. El análisis de los residuales del modelo Prophet revela cierta heterogeneidad, con algunos picos que sugieren valores atípicos. La distribución de los residuales también muestra ligera asimetría, lo que podría implicar incumplimiento parcial de los supuestos de normalidad. Esto sugiere oportunidades de mejora en el manejo de la variabilidad inherente a la serie temporal. Una fortaleza del modelo Prophet es su enfoque de regresión, el cual permite una mejor comprensión de los factores que influyen en la precipitación. Esto abre la posibilidad de incorporar variables meteorológicas adicionales, enriqueciendo el análisis y la capacidad predictiva del modelo. En conclusión, el modelo Prophet ha demostrado un desempeño superior al modelo ARIMA, con métricas de error más bajas. Sin embargo, persisten algunos desafíos relacionados con la heterogeneidad de la serie y el cumplimiento de supuestos estadísticos. El enfoque de regresión del modelo Prophet ofrece oportunidades para futuras mejoras, como la inclusión de variables explicativas adicionales. "],["redes-neuronales.html", "Sección 7 Redes Neuronales para Pronóstico de Precipitación 7.1 Metodología 7.2 Análisis de Resultados", " Sección 7 Redes Neuronales para Pronóstico de Precipitación El pronóstico de precipitación es una tarea desafiante debido a la naturaleza compleja y altamente variable de los fenómenos meteorológicos. En este proyecto, exploraremos el uso de técnicas de redes neuronales recurrentes, específicamente las arquitecturas Elman y Jordan, para modelar y predecir series temporales de precipitación. 7.1 Metodología La metodología se centra en la aplicación de dos arquitecturas de redes neuronales: Elman y Jordan. Estas redes neuronales recurrentes ofrecen capacidades únicas para capturar las dependencias temporales inherentes a los datos de precipitación, permitiendo modelar la compleja dinámica de las series temporales meteorológicas. El enfoque metodológico se estructura en tres etapas principales: Preparación y transformación de datos Entrenamiento de modelos de redes neuronales Evaluación y análisis comparativo de los resultados A continuación, se detallarán cada una de estas etapas, describiendo los procedimientos técnicos, las decisiones de procesamiento y las estrategias de modelado implementadas para abordar el desafío de predecir series temporales de precipitación. 7.1.1 Preparación de Datos para Redes Neuronales El análisis de series temporales con redes neuronales requiere una cuidadosa preparación de los datos. En este caso, aplicaremos una transformación logarítmica a los datos de precipitación, seguida de la creación de variables de retardo para capturar la dependencia temporal. 7.1.1.1 Transformación Logarítmica de Datos de Precipitación La transformación logarítmica es una técnica fundamental en el preprocesamiento de series temporales de precipitación. Esto presenta varios beneficios: Estabilización de la Varianza: Los datos de precipitación suelen tener alta variabilidad y asimetría. El logaritmo ayuda a comprimir la escala de valores extremos, reduciendo la dispersión de los datos. Normalización de la Distribución: Muchas series de precipitación tienen una distribución sesgada hacia la derecha. El logaritmo tiende a aproximar la distribución a una forma más simétrica y cercana a la normalidad. Mejor Rendimiento en Modelos de Aprendizaje Automático: Las redes neuronales generalmente procesan mejor datos con distribuciones más uniformes y rangos de valores más reducidos. Tratamiento de Valores Cercanos a Cero: Utilizamos log1p() (logaritmo natural de 1 + x) para manejar adecuadamente valores de precipitación muy bajos o cero, evitando problemas matemáticos. Code # Transformación logarítmica de la serie temporal ts_lluvia_log &lt;- log1p(ts_lluvia) # Convertir ts a vector valor &lt;- as.vector(ts_lluvia_log) 7.1.1.2 Creación de Variables de Retardo Para capturar la dependencia temporal de la serie de precipitación, creamos un conjunto de variables de retardo. Específicamente, utilizamos los 10 valores anteriores como variables de entrada, lo que permite a la red neuronal aprender patrones y estructuras a corto plazo. Code # Crear dataframe con rezagos df_serie &lt;- data.frame( valor = valor, x1 = stats::lag(valor, 1), x2 = stats::lag(valor, 2), x3 = stats::lag(valor, 3), x4 = stats::lag(valor, 4), x5 = stats::lag(valor, 5), x6 = stats::lag(valor, 6), x7 = stats::lag(valor, 7), x8 = stats::lag(valor, 8), x9 = stats::lag(valor, 9), x10 = stats::lag(valor, 10) ) # Eliminar filas con NA df_serie &lt;- df_serie %&gt;% na.omit() # Definir conjuntos de entrenamiento y prueba n &lt;- nrow(df_serie) train &lt;- 1:floor(0.9*n) # Preparar inputs y outputs inputs &lt;- as.matrix(df_serie[, 2:11]) outputs &lt;- df_serie$valor 7.1.1.3 Normalización de Datos La normalización es un paso crucial en el preprocesamiento de datos para redes neuronales. Permite escalar los valores de entrada y salida a un rango uniforme (generalmente entre 0 y 1), lo que mejora la convergencia del algoritmo de aprendizaje y ayuda a la red a procesar los datos más eficientemente. Code # Normalización de datos inputs_norm &lt;- (inputs - min(inputs)) / (max(inputs) - min(inputs)) outputs_norm &lt;- (outputs - min(outputs)) / (max(outputs) - min(outputs)) 7.1.2 Entrenamiento de Modelos de Redes Neuronales Procedemos a entrenar dos modelos de redes neuronales recurrentes: Elman y Jordan. Ambas arquitecturas están diseñadas para capturar dependencias temporales en series de tiempo. 7.1.2.1 Red Neuronal Elman Las redes de Elman son un tipo de red neuronal recurrente que incluye una capa de contexto, lo que les permite mantener un estado interno y capturar dependencias temporales en series de tiempo. En nuestro análisis, utilizaremos una arquitectura con dos capas ocultas para modelar la serie de precipitación. Code # Ajuste de entrenamiento y test inputs_train &lt;- inputs_norm[train, ] inputs_test &lt;- inputs_norm[-train, ] outputs_train &lt;- outputs_norm[train] outputs_test &lt;- outputs_norm[-train] # Entrenar red Elman fit_elman &lt;- elman(inputs_train, outputs_train, size = c(3, 2), # Dos capas ocultas learnFuncParams = c(0.1), maxit = 5000) # Visualizar error iterativo plotIterativeError(fit_elman) title(&quot;Error Iterativo - Red Elman&quot;) Se puede observar que el error comienza en un valor cercano a 200 y disminuye progresivamente a medida que el modelo se entrena, estabilizándose alrededor de 0 después de aproximadamente 5000 iteraciones. Este gráfico nos permite visualizar la convergencia del modelo Elman durante el proceso de optimización. Code # Predicción con Elman pred_elman_norm &lt;- predict(fit_elman, inputs_test) pred_elman &lt;- pred_elman_norm * (max(outputs) - min(outputs)) + min(outputs) # Visualización de predicciones plot(outputs_test, type = &quot;l&quot;, main = &quot;Predicción de Precipitación - Red Elman&quot;, xlab = &quot;Tiempo&quot;, ylab = &quot;Precipitación (mm)&quot;) lines(pred_elman, col = &quot;red&quot;) legend(&quot;topright&quot;, legend = c(&quot;Valor Real&quot;, &quot;Predicción Elman&quot;), col = c(&quot;black&quot;, &quot;red&quot;), lty = 1) Se puede observar que el modelo Elman logra capturar la dinámica general de la serie temporal, aunque presenta dificultades para predecir con precisión los picos y fluctuaciones de la precipitación. Esta visualización nos permite evaluar el desempeño del modelo Elman en términos de su capacidad para reproducir los patrones de precipitación. 7.1.2.2 Red Neuronal Jordan Las redes de Jordan son otra variante de redes neuronales recurrentes, caracterizadas por realimentar la salida de la red como parte de la entrada en la siguiente iteración. Esta arquitectura puede ser particularmente útil para capturar patrones secuenciales en series temporales. Code # Entrenar red Jordan fit_jordan &lt;- jordan(inputs_train, outputs_train, size = 4, # Una capa oculta learnFuncParams = c(0.01), maxit = 5000) # Predicción con Jordan pred_jordan_norm &lt;- predict(fit_jordan, inputs_test) pred_jordan &lt;- pred_jordan_norm * (max(outputs) - min(outputs)) + min(outputs) # Visualización de predicciones plot(outputs_test, type = &quot;l&quot;, main = &quot;Predicción de Precipitación - Red Jordan&quot;, xlab = &quot;Tiempo&quot;, ylab = &quot;Precipitación (mm)&quot;) lines(pred_jordan, col = &quot;red&quot;) legend(&quot;topright&quot;, legend = c(&quot;Valor Real&quot;, &quot;Predicción Jordan&quot;), col = c(&quot;black&quot;, &quot;red&quot;), lty = 1) Al igual que en el caso del modelo Elman, el modelo Jordan parece capturar la tendencia general de la serie temporal, pero también presenta dificultades para predecir con precisión los valores extremos de precipitación. Esta visualización nos permite comparar el desempeño del modelo Jordan con el del modelo Elman en términos de su capacidad para modelar la dinámica de la precipitación. 7.1.3 Evaluación de Modelos Para evaluar el desempeño de los modelos, calculamos métricas de error estándar, como el Error Cuadrático Medio (RMSE), el Error Absoluto Medio (MAE) y el Error Porcentual Absoluto Medio (MAPE). Aplicamos la transformación inversa a los valores predichos para obtener las métricas en la escala original de los datos. Code # Función para calcular métricas de error con transformación inversa calcular_metricas &lt;- function(real_log, pred_elman_log, pred_jordan_log) { # Transformación inversa (exponencial) real &lt;- expm1(real_log) pred_elman &lt;- expm1(pred_elman_log) pred_jordan &lt;- expm1(pred_jordan_log) # Métricas para Elman rmse_elman &lt;- sqrt(mean((real - pred_elman)^2)) mae_elman &lt;- mean(abs(real - pred_elman)) mape_elman &lt;- mean(abs((real - pred_elman) / real)) * 100 # Métricas para Jordan rmse_jordan &lt;- sqrt(mean((real - pred_jordan)^2)) mae_jordan &lt;- mean(abs(real - pred_jordan)) mape_jordan &lt;- mean(abs((real - pred_jordan) / real)) * 100 # Crear dataframe de resultados return(data.frame( Modelo = c(&quot;Red Elman&quot;, &quot;Red Jordan&quot;), RMSE = c(rmse_elman, rmse_jordan), MAE = c(mae_elman, mae_jordan), MAPE = c(mape_elman, mape_jordan) )) } # Calcular métricas con datos transformados metricas_nn &lt;- calcular_metricas( outputs_test, pred_elman_norm * (max(outputs) - min(outputs)) + min(outputs), pred_jordan_norm * (max(outputs) - min(outputs)) + min(outputs) ) kable(metricas_nn, caption = &quot;Métricas de Error - Redes Neuronales&quot;) Table 7.1: Métricas de Error - Redes Neuronales Modelo RMSE MAE MAPE Red Elman 6.243833 3.229842 Inf Red Jordan 6.218353 3.230064 Inf La tabla de métricas muestra los valores de RMSE, MAE y MAPE para los modelos Elman y Jordan. Ambos modelos presentan valores similares de RMSE y MAE, lo que indica que tienen un desempeño comparable en términos de la magnitud de los errores de predicción. Sin embargo, el valor de MAPE es infinito para ambos modelos, lo que sugiere que estos presentan dificultades para predecir con precisión los valores reales de precipitación, especialmente en los casos de valores bajos o cercanos a cero. Esta información complementa el análisis visual de las predicciones y nos permite evaluar de manera más completa el desempeño de los dos modelos de redes neuronales. 7.2 Análisis de Resultados Los modelos de redes neuronales Elman y Jordan aplicados al pronóstico de precipitación han mostrado un desempeño aceptable, con métricas de error relativamente bajas. Sin embargo, es importante analizar en detalle los resultados obtenidos para identificar oportunidades de mejora. En primer lugar, la transformación logarítmica aplicada a los datos de precipitación ha sido un paso crucial en el preprocesamiento. Esta técnica ha ayudado a estabilizar la varianza y aproximar la distribución de los datos a una forma más simétrica, lo cual es deseable para el entrenamiento de redes neuronales. No obstante, el hecho de que el MAPE (Error Porcentual Absoluto Medio) arroje un valor “Inf” (infinito) sugiere que aún existen problemas con valores de precipitación muy cercanos a cero. En cuanto a la arquitectura de las redes neuronales, los modelos Elman y Jordan han logrado capturar las dependencias temporales de la serie de precipitación. Sin embargo, hay margen para explorar configuraciones más complejas, como la incorporación de más capas ocultas o el uso de arquitecturas más avanzadas como LSTM y GRU, las cuales podrían mejorar aún más la capacidad de modelado. Adicionalmente, la selección de variables de entrada es un aspecto clave a considerar. Si bien los 10 rezagos temporales utilizados han sido un buen punto de partida, sería interesante evaluar la inclusión de otras variables predictoras, como datos meteorológicos (temperatura, humedad, presión atmosférica, etc.), que podrían aportar información relevante y mejorar el desempeño de los modelos. En cuanto a la validación y evaluación de los modelos, si bien se ha realizado una división de los datos en conjuntos de entrenamiento y prueba, la implementación de técnicas de validación cruzada podría proporcionar una estimación más robusta del desempeño de los modelos. Además, un análisis detallado de los residuos y su distribución podría revelar patrones o problemas que deban abordarse. En resumen, los modelos de redes neuronales Elman y Jordan han demostrado un desempeño aceptable en el pronóstico de precipitación, pero existen oportunidades de mejora relacionadas con el tratamiento de valores extremos, la selección de arquitecturas más avanzadas, la inclusión de variables predictoras adicionales y la aplicación de técnicas de validación más robustas. Continuar explorando estos aspectos y comparar los resultados con otros métodos de modelado permitirá refinar aún más la capacidad predictiva de estos enfoques. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
